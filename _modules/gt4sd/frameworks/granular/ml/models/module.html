

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>gt4sd.frameworks.granular.ml.models.module &mdash; gt4sd  documentation</title>
  

  
  <link rel="stylesheet" href="../../../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../../../" src="../../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../../_static/jquery.js"></script>
        <script src="../../../../../../_static/underscore.js"></script>
        <script src="../../../../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../../../index.html" class="icon icon-home"> gt4sd
          

          
            
            <img src="../../../../../../_static/gt4sd_logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../source/gt4sd_inference_usage_md.html">Examples on how to use the GT4SD algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../source/gt4sd_algorithm_addition_md.html">Examples on how to add an algorithm to GT4SD</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../api/gt4sd.html">API of the gt4sd package</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../index.html">gt4sd</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../../../index.html">Module code</a> &raquo;</li>
        
      <li>gt4sd.frameworks.granular.ml.models.module</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for gt4sd.frameworks.granular.ml.models.module</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Generic modules.&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="kn">from</span> <span class="nn">....torch</span> <span class="kn">import</span> <span class="n">get_device_from_tensor</span>
<span class="kn">from</span> <span class="nn">...tokenizer</span> <span class="kn">import</span> <span class="n">Tokenizer</span>
<span class="kn">from</span> <span class="nn">.activation</span> <span class="kn">import</span> <span class="n">ACTIVATION_FACTORY</span>


<div class="viewcode-block" id="Mlp"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.Mlp">[docs]</a><span class="k">class</span> <span class="nc">Mlp</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;MLP module.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="Mlp.__init__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.Mlp.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">output_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">activation</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Construct Mlp.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_size: size of the input.</span>
<span class="sd">            hidden_size: size of the hidden layers.</span>
<span class="sd">            output_size: size of the output.</span>
<span class="sd">            n_layers: number of layers.</span>
<span class="sd">            activation: name of the activation.</span>
<span class="sd">            dropout: dropout rate.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">ACTIVATION_FACTORY</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">activation</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">first_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="n">middle_layers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
            <span class="n">middle_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
            <span class="n">middle_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
            <span class="n">middle_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">middle_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">middle_layers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_size</span></div>

<div class="viewcode-block" id="Mlp.forward"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.Mlp.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward pass in the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: model input.</span>

<span class="sd">        Returns:</span>
<span class="sd">            model output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">first_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">middle_layers</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_layer</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">:</span>
            <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span></div></div>


<div class="viewcode-block" id="MlpEncoder"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.MlpEncoder">[docs]</a><span class="k">class</span> <span class="nc">MlpEncoder</span><span class="p">(</span><span class="n">Mlp</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;MLP encoder.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="MlpEncoder.__init__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.MlpEncoder.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">output_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">activation</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Construct MlpEncoder.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_size: size of the input.</span>
<span class="sd">            hidden_size: size of the hidden layers.</span>
<span class="sd">            output_size: size of the output.</span>
<span class="sd">            n_layers: number of layers.</span>
<span class="sd">            activation: name of the activation.</span>
<span class="sd">            dropout: dropout rate. Defaults to 0.0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="n">input_size</span><span class="p">,</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">output_size</span><span class="o">=</span><span class="n">output_size</span><span class="p">,</span>
            <span class="n">n_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="MlpDecoder"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.MlpDecoder">[docs]</a><span class="k">class</span> <span class="nc">MlpDecoder</span><span class="p">(</span><span class="n">Mlp</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;MLP decoder.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="MlpDecoder.__init__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.MlpDecoder.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">latent_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">output_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">activation</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Construct MlpEncoder.</span>

<span class="sd">        Args:</span>
<span class="sd">            latent_size: size of the input.</span>
<span class="sd">            hidden_size: size of the hidden layers.</span>
<span class="sd">            output_size: size of the output.</span>
<span class="sd">            n_layers: number of layers.</span>
<span class="sd">            activation: name of the activation.</span>
<span class="sd">            dropout: dropout rate. Defaults to 0.0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="n">latent_size</span><span class="p">,</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">output_size</span><span class="o">=</span><span class="n">output_size</span><span class="p">,</span>
            <span class="n">n_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="RnnEncoder"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.RnnEncoder">[docs]</a><span class="k">class</span> <span class="nc">RnnEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;RNN encoder.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="RnnEncoder.__init__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.RnnEncoder.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">embedding_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">bidirectional</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">latent_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">196</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Construct RnnEncoder.</span>

<span class="sd">        Args:</span>
<span class="sd">            vocab_size: size of the vocabulary.</span>
<span class="sd">            embedding_size: size of the embedding vectors.</span>
<span class="sd">            hidden_size: hidden size. Defaults to 256.</span>
<span class="sd">            n_layers: number of layers. Defaults to 2.</span>
<span class="sd">            bidirectional: whether the RNN cell is bidirectional. Defaults to False.</span>
<span class="sd">            latent_size: latent size. Defaults to 196.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">embedding_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bidirectional</span> <span class="o">=</span> <span class="n">bidirectional</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_size</span> <span class="o">=</span> <span class="n">latent_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_factor</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="k">if</span> <span class="n">bidirectional</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="n">embedding_size</span><span class="p">,</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span>
            <span class="n">bidirectional</span><span class="o">=</span><span class="n">bidirectional</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
            <span class="n">num_embeddings</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_size</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="RnnEncoder.forward"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.RnnEncoder.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">input_sequence</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Forward pass in the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_sequence: input sequence tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            a tuple containing hidden state and embedded sequence.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">input_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">input_sequence</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">input_embedding</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">hidden</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">hidden</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">hidden</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">input_embedding</span></div></div>


<div class="viewcode-block" id="RnnDecoder"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.RnnDecoder">[docs]</a><span class="k">class</span> <span class="nc">RnnDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;RNN decoder.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="RnnDecoder.__init__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.RnnDecoder.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">embedding_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">latent_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">196</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Construct RnnDecoder.</span>

<span class="sd">        Args:</span>
<span class="sd">            vocab_size: size of the vocabulary.</span>
<span class="sd">            embedding_size: size of the embedding vectors.</span>
<span class="sd">            hidden_size: hidden size. Defaults to 256.</span>
<span class="sd">            n_layers: number of layers. Defaults to 2.</span>
<span class="sd">            latent_size: latent size. Defaults to 196.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_size</span> <span class="o">=</span> <span class="n">latent_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_factor</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="n">embedding_size</span><span class="p">,</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent2hidden</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span>
            <span class="n">latent_size</span><span class="p">,</span> <span class="n">hidden_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_factor</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs2vocab</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span></div>

<div class="viewcode-block" id="RnnDecoder.forward"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.RnnDecoder.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">latent</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">input_embedding</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward pass in the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            latent: latent tensor.</span>
<span class="sd">            input_embedding: input embedding.</span>

<span class="sd">        Returns:</span>
<span class="sd">            model output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent2hidden</span><span class="p">(</span><span class="n">latent</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">hidden</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_factor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">hidden</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">input_embedding</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">hsize</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">hsize</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs2vocab</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">outputs</span></div>

<div class="viewcode-block" id="RnnDecoder.inference_direct"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.RnnDecoder.inference_direct">[docs]</a>    <span class="k">def</span> <span class="nf">inference_direct</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">latent</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">embedding</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Tokenizer</span><span class="p">,</span>
        <span class="n">max_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Direct inference from latent space.</span>

<span class="sd">        Args:</span>
<span class="sd">            latent: latent tensor.</span>
<span class="sd">            embedding: embedding module.</span>
<span class="sd">            tokenizer: tokenizer.</span>
<span class="sd">            max_len: maximum sequence length.</span>

<span class="sd">        Returns:</span>
<span class="sd">            a tuple containing decoded strings and indices.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">latent</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent2hidden</span><span class="p">(</span><span class="n">latent</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">hidden</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_factor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">hidden</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>
        <span class="n">input_sequence</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
            <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">sos_token_id</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">latent</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="n">logits_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_len</span><span class="p">):</span>
            <span class="n">input_embedding</span> <span class="o">=</span> <span class="n">embedding</span><span class="p">(</span><span class="n">input_sequence</span><span class="p">)</span>
            <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">input_embedding</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs2vocab</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
            <span class="n">logits_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
            <span class="n">input_sequence</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">logits_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">logits_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">token_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits_tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">decoded_texts</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_id_to_token</span><span class="p">(</span><span class="n">vocab_index</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                <span class="k">for</span> <span class="n">vocab_index</span> <span class="ow">in</span> <span class="n">token_indices</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
            <span class="p">]</span>
            <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">decoded_texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">decoded_texts</span><span class="p">,</span> <span class="n">token_indices</span></div></div>


<div class="viewcode-block" id="attention"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.attention">[docs]</a><span class="k">def</span> <span class="nf">attention</span><span class="p">(</span>
    <span class="n">query</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">key</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">dropout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Compute scaled dot product attention (adapted from Viswani et al.).</span>

<span class="sd">    Args:</span>
<span class="sd">        query: query tensor.</span>
<span class="sd">        key: key tensor.</span>
<span class="sd">        value: value tesor.</span>
<span class="sd">        mask: mask to apply on attention score. Defaults to None, a.k.a., no mask.</span>
<span class="sd">        dropout: dropout layer. Defaults to None, a.k.a., no dropout.</span>

<span class="sd">    Returns:</span>
<span class="sd">        a tuple containing the applied attention and the attention weights.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">d_k</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d_k</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1e9</span><span class="p">)</span>
    <span class="n">p_attn</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">p_attn</span> <span class="o">=</span> <span class="n">dropout</span><span class="p">(</span><span class="n">p_attn</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">p_attn</span><span class="p">,</span> <span class="n">value</span><span class="p">),</span> <span class="n">p_attn</span></div>


<div class="viewcode-block" id="clones"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.clones">[docs]</a><span class="k">def</span> <span class="nf">clones</span><span class="p">(</span><span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Produce N identical layers (adapted from http://nlp.seas.harvard.edu/2018/04/03/attention.html).</span>

<span class="sd">    Args:</span>
<span class="sd">        module: a module.</span>
<span class="sd">        n: number of clones.</span>

<span class="sd">    Returns:</span>
<span class="sd">        a module list.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">module</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span></div>


<div class="viewcode-block" id="subsequent_mask"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.subsequent_mask">[docs]</a><span class="k">def</span> <span class="nf">subsequent_mask</span><span class="p">(</span><span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Mask out subsequent positions (adapted from http://nlp.seas.harvard.edu/2018/04/03/attention.html).</span>

<span class="sd">    Args:</span>
<span class="sd">        size: size of the attention matrix.</span>

<span class="sd">    Returns:</span>
<span class="sd">        the mask tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">attn_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
    <span class="n">subsequent_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">attn_shape</span><span class="p">),</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;uint8&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">subsequent_mask</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span></div>


<div class="viewcode-block" id="ListModule"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.ListModule">[docs]</a><span class="k">class</span> <span class="nc">ListModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create single pytorch module from list of modules.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="ListModule.__init__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.ListModule.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Construct ListModule.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">module</span><span class="p">)</span>
            <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span></div>

<div class="viewcode-block" id="ListModule.__getitem__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.ListModule.__getitem__">[docs]</a>    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Get item from the module list.</span>

<span class="sd">        Args:</span>
<span class="sd">            idx: index of the item.</span>

<span class="sd">        Raises:</span>
<span class="sd">            IndexError: in case the index is out of range.</span>

<span class="sd">        Returns:</span>
<span class="sd">            the item.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="s2">&quot;index </span><span class="si">{}</span><span class="s2"> is out of range&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
        <span class="n">it</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">idx</span><span class="p">):</span>
            <span class="nb">next</span><span class="p">(</span><span class="n">it</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="n">it</span><span class="p">)</span></div>

<div class="viewcode-block" id="ListModule.__iter__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.ListModule.__iter__">[docs]</a>    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;An iterator over the module list values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            the iterator over values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">())</span></div>

<div class="viewcode-block" id="ListModule.__len__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.ListModule.__len__">[docs]</a>    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Length of the module list.</span>

<span class="sd">        Returns:</span>
<span class="sd">            the number of modules.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="MultiHeadedAttention"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.MultiHeadedAttention">[docs]</a><span class="k">class</span> <span class="nc">MultiHeadedAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Multihead attention implementation (based on Vaswani et al.).&quot;&quot;&quot;</span>

<div class="viewcode-block" id="MultiHeadedAttention.__init__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.MultiHeadedAttention.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Construct MultiHeadedAttention.</span>

<span class="sd">        Args:</span>
<span class="sd">            h: number of heads.</span>
<span class="sd">            d_model: model size.</span>
<span class="sd">            dropout: dropout rate. Defaults to 0.1.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">d_model</span> <span class="o">%</span> <span class="n">h</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="c1"># we assume d_v always equals d_k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">//</span> <span class="n">h</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">h</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linears</span> <span class="o">=</span> <span class="n">clones</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">),</span> <span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span></div>

<div class="viewcode-block" id="MultiHeadedAttention.forward"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.MultiHeadedAttention.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">query</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_attn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward pass in the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            query: query tensor.</span>
<span class="sd">            key: key tensor.</span>
<span class="sd">            value: value tesor.</span>
<span class="sd">            mask: mask to apply on attention score. Defaults to None, a.k.a., no mask.</span>
<span class="sd">            return_attn: whether to return the attention matrix instead of the linear layer output.</span>
<span class="sd">                Defaults to False, a.k.a, do not return attention.</span>

<span class="sd">        Returns:</span>
<span class="sd">            either the last layer output of the attention matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Same mask applied to all h heads</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">nbatches</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># 1) do all the linear projections in batch from d_model =&gt; h x d_k</span>
        <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">linear_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">nbatches</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">linear_layer</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linears</span><span class="p">,</span> <span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">))</span>  <span class="c1"># type:ignore</span>
        <span class="p">]</span>

        <span class="c1"># 2) apply attention on all the projected vectors in batch</span>
        <span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">attention</span><span class="p">(</span>  <span class="c1"># type:ignore</span>
            <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span>
        <span class="p">)</span>  <span class="c1"># type:ignore</span>

        <span class="c1"># 3) &quot;concat&quot; using a view and apply a final linear</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">nbatches</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">return_attn</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linears</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># type:ignore</span></div></div>


<div class="viewcode-block" id="PositionwiseFeedForward"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.PositionwiseFeedForward">[docs]</a><span class="k">class</span> <span class="nc">PositionwiseFeedForward</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Feed forward implementation.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="PositionwiseFeedForward.__init__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.PositionwiseFeedForward.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">d_ff</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Construct PositionwiseFeedForward.</span>

<span class="sd">        Args:</span>
<span class="sd">            d_model: model size.</span>
<span class="sd">            d_ff: feed forward size.</span>
<span class="sd">            dropout: dropout rate. Defaults to 0.1.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_ff</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_ff</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span></div>

<div class="viewcode-block" id="PositionwiseFeedForward.forward"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.PositionwiseFeedForward.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward pass in the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            feed forward output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w_1</span><span class="p">(</span><span class="n">x</span><span class="p">))))</span></div></div>


<div class="viewcode-block" id="ConvBottleneck"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.ConvBottleneck">[docs]</a><span class="k">class</span> <span class="nc">ConvBottleneck</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Set of convolutional layers to reduce memory matrix to single latent vector.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="ConvBottleneck.__init__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.ConvBottleneck.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">number_of_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Construct ConvBottleneck.</span>

<span class="sd">        Args:</span>
<span class="sd">            size: input size.</span>
<span class="sd">            number_of_layers: convolutional layers number. Defaults to 3.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">conv_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">in_d</span> <span class="o">=</span> <span class="n">size</span>
        <span class="n">first</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_of_layers</span><span class="p">):</span>
            <span class="n">out_d</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">in_d</span> <span class="o">-</span> <span class="mi">64</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">64</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">first</span><span class="p">:</span>
                <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">9</span>
                <span class="n">first</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">8</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">out_d</span> <span class="o">=</span> <span class="mi">64</span>
            <span class="n">conv_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">in_d</span><span class="p">,</span> <span class="n">out_d</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
            <span class="p">)</span>
            <span class="n">in_d</span> <span class="o">=</span> <span class="n">out_d</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_layers</span> <span class="o">=</span> <span class="n">ListModule</span><span class="p">(</span><span class="o">*</span><span class="n">conv_layers</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConvBottleneck.forward"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.ConvBottleneck.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward pass in the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            model output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">conv</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_layers</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span></div></div>


<div class="viewcode-block" id="DeconvBottleneck"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.DeconvBottleneck">[docs]</a><span class="k">class</span> <span class="nc">DeconvBottleneck</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Set of deconvolutional layers to reshape latent vector back into memory matrix.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="DeconvBottleneck.__init__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.DeconvBottleneck.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dim_factor</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Construct DeconvBottleneck.</span>

<span class="sd">        Args:</span>
<span class="sd">            size: size of the deconvolutional padding.</span>
<span class="sd">            seq_len: length of the sequence.</span>
<span class="sd">            dim_factor: dimensionality factor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">deconv_layers</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">in_d</span> <span class="o">=</span> <span class="mi">64</span>

        <span class="n">out_fac</span> <span class="o">=</span> <span class="mi">9</span> <span class="o">*</span> <span class="n">dim_factor</span> <span class="o">+</span> <span class="mi">8</span>
        <span class="n">out_fac</span> <span class="o">=</span> <span class="n">out_fac</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">50</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">diff_seq</span> <span class="o">=</span> <span class="n">out_fac</span> <span class="o">-</span> <span class="n">seq_len</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
            <span class="n">out_d</span> <span class="o">=</span> <span class="p">(</span><span class="n">size</span> <span class="o">-</span> <span class="n">in_d</span><span class="p">)</span> <span class="o">//</span> <span class="mi">4</span> <span class="o">+</span> <span class="n">in_d</span>
            <span class="n">stride</span> <span class="o">=</span> <span class="mi">3</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="mi">3</span>
            <span class="n">dilation</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">11</span>
            <span class="n">output_padding</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">out_d</span> <span class="o">=</span> <span class="n">size</span>
                <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="n">dilation</span> <span class="o">=</span> <span class="mi">5</span>
                <span class="k">if</span> <span class="n">diff_seq</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">padding</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">diff_seq</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
                    <span class="n">output_padding</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">padding</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">diff_seq</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
                    <span class="n">output_padding</span> <span class="o">=</span> <span class="mi">1</span>

            <span class="n">deconv_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose1d</span><span class="p">(</span>
                        <span class="n">in_d</span><span class="p">,</span>
                        <span class="n">out_d</span><span class="p">,</span>
                        <span class="n">kernel_size</span><span class="p">,</span>
                        <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
                        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
                        <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                        <span class="n">output_padding</span><span class="o">=</span><span class="n">output_padding</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="n">in_d</span> <span class="o">=</span> <span class="n">out_d</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">deconv_layers</span> <span class="o">=</span> <span class="n">ListModule</span><span class="p">(</span><span class="o">*</span><span class="n">deconv_layers</span><span class="p">)</span></div>

<div class="viewcode-block" id="DeconvBottleneck.forward"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.DeconvBottleneck.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward pass in the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            model output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">deconv</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">deconv_layers</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">deconv</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span></div></div>


<div class="viewcode-block" id="Embeddings"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.Embeddings">[docs]</a><span class="k">class</span> <span class="nc">Embeddings</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s2">&quot;Transforms input token id tensors to size d_model embeddings.&quot;</span>

<div class="viewcode-block" id="Embeddings.__init__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.Embeddings.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Costruct Embeddings.</span>

<span class="sd">        Args:</span>
<span class="sd">            d_model: size of the embedding vectors.</span>
<span class="sd">            vocab_size: size of the vocabulary.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lut</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span></div>

<div class="viewcode-block" id="Embeddings.forward"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.Embeddings.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward pass in the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            model output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">lut</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="PositionalEncoding"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.PositionalEncoding">[docs]</a><span class="k">class</span> <span class="nc">PositionalEncoding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Static sinusoidal positional encoding layer.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="PositionalEncoding.__init__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.PositionalEncoding.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">max_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5000</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Construct PositionalEncoding.</span>

<span class="sd">        Args:</span>
<span class="sd">            d_model: model size.</span>
<span class="sd">            dropout: dropout rate.</span>
<span class="sd">            max_len: maximum sequence length. Defaults to 5000.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>

        <span class="c1"># compute the positional encodings once in log space</span>
        <span class="n">pe</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="n">position</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">div_term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">10000.0</span><span class="p">)</span> <span class="o">/</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="n">pe</span> <span class="o">=</span> <span class="n">pe</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;pe&quot;</span><span class="p">,</span> <span class="n">pe</span><span class="p">)</span></div>

<div class="viewcode-block" id="PositionalEncoding.forward"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.PositionalEncoding.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward pass in the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            model output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="p">[:,</span> <span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span>  <span class="c1"># type:ignore</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="TorchLayerNorm"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.TorchLayerNorm">[docs]</a><span class="k">class</span> <span class="nc">TorchLayerNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Layer normalization using torch BatchNorm1d.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="TorchLayerNorm.__init__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.TorchLayerNorm.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Construct TorchLayerNorm.</span>

<span class="sd">        Args:</span>
<span class="sd">            features: number of features.</span>
<span class="sd">            eps: espilon to add to denominator for numerical stability. Defaults to 1e-6.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">)</span></div>

<div class="viewcode-block" id="TorchLayerNorm.forward"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.TorchLayerNorm.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward pass in the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            model output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="LayerNorm"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.LayerNorm">[docs]</a><span class="k">class</span> <span class="nc">LayerNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Custom layer normalization.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="LayerNorm.__init__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.LayerNorm.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Construct LayerNorm.</span>

<span class="sd">        Args:</span>
<span class="sd">            features: number of features.</span>
<span class="sd">            eps: espilon to add to denominator for numerical stability. Defaults to 1e-6.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">features</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">features</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span></div>

<div class="viewcode-block" id="LayerNorm.forward"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.LayerNorm.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward pass in the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            model output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">a</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">std</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span></div></div>


<div class="viewcode-block" id="SublayerConnection"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.SublayerConnection">[docs]</a><span class="k">class</span> <span class="nc">SublayerConnection</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A residual connection followed by a layer normalization.</span>

<span class="sd">    Note for code simplicity the norm is first as opposed to last. A dropout layer</span>
<span class="sd">    is also applied.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="SublayerConnection.__init__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.SublayerConnection.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span></div>

<div class="viewcode-block" id="SublayerConnection.forward"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.SublayerConnection.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">sublayer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward pass in the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: input tensor.</span>
<span class="sd">            sublayer: a callable returning a tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            model output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">sublayer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span></div></div>


<div class="viewcode-block" id="TransformerEncoder"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.TransformerEncoder">[docs]</a><span class="k">class</span> <span class="nc">TransformerEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base transformer encoder architecture.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="TransformerEncoder.__init__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.TransformerEncoder.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">ff_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">n_layers_enc</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">bypass_bottleneck</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Construct TransformerEncoder.</span>

<span class="sd">        Args:</span>
<span class="sd">            hidden_size: hidden size.</span>
<span class="sd">            ff_size: feed forward size.</span>
<span class="sd">            seq_len: sequence length.</span>
<span class="sd">            dropout: dropout rate.</span>
<span class="sd">            heads: number of heads.</span>
<span class="sd">            n_layers_enc: number of encoding layers.</span>
<span class="sd">            vocab_size: vocabulary size.</span>
<span class="sd">            bypass_bottleneck: whether the bottleneck should be by passed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">position</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">Embeddings</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">position</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span> <span class="o">=</span> <span class="n">MultiHeadedAttention</span><span class="p">(</span><span class="n">heads</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward</span> <span class="o">=</span> <span class="n">PositionwiseFeedForward</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">ff_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="n">layer</span> <span class="o">=</span> <span class="n">TransformerEncoderLayer</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward</span><span class="p">,</span> <span class="n">dropout</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">clones</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">n_layers_enc</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv_bottleneck</span> <span class="o">=</span> <span class="n">ConvBottleneck</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">bypass_bottleneck</span> <span class="o">=</span> <span class="n">bypass_bottleneck</span>
        <span class="n">conv_output_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calc_output_shape</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_output_len</span> <span class="o">=</span> <span class="n">conv_output_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">conv_output_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_output_shape</span> <span class="o">=</span> <span class="n">conv_output_shape</span></div>

<div class="viewcode-block" id="TransformerEncoder.calc_output_shape"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.TransformerEncoder.calc_output_shape">[docs]</a>    <span class="k">def</span> <span class="nf">calc_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute output shape.</span>

<span class="sd">        Args:</span>
<span class="sd">            seq_len: sequence length.</span>
<span class="sd">            hidden_size: hidden size.</span>

<span class="sd">        Returns:</span>
<span class="sd">            convolutional bottleneck output shape.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">))</span>
        <span class="n">x_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_bottleneck</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_out</span><span class="o">.</span><span class="n">shape</span></div>

<div class="viewcode-block" id="TransformerEncoder.forward"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.TransformerEncoder.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward pass in the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: input tensor.</span>
<span class="sd">            mask: mask to apply in the attention layer.</span>

<span class="sd">        Returns:</span>
<span class="sd">            model output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">attn_layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>  <span class="c1"># type:ignore</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">attn_layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
        <span class="n">mem</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">mem</span> <span class="o">=</span> <span class="n">mem</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">mem</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_bottleneck</span><span class="p">(</span><span class="n">mem</span><span class="p">)</span>
        <span class="n">mem</span> <span class="o">=</span> <span class="n">mem</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">mem</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mem</span></div></div>


<div class="viewcode-block" id="TransformerEncoderLayer"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.TransformerEncoderLayer">[docs]</a><span class="k">class</span> <span class="nc">TransformerEncoderLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Self-attention/feedforward implementation.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="TransformerEncoderLayer.__init__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.TransformerEncoderLayer.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">self_attn</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">feed_forward</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Construct TransformerEncoderLayer.</span>

<span class="sd">        Args:</span>
<span class="sd">            size: model size.</span>
<span class="sd">            seq_len: sequence length.</span>
<span class="sd">            self_attn: self-attention layer.</span>
<span class="sd">            feed_forward: feed forward layer.</span>
<span class="sd">            dropout: droupout rate.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">seq_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span> <span class="o">=</span> <span class="n">self_attn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward</span> <span class="o">=</span> <span class="n">feed_forward</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sublayer</span> <span class="o">=</span> <span class="n">clones</span><span class="p">(</span><span class="n">SublayerConnection</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span></div>

<div class="viewcode-block" id="TransformerEncoderLayer.forward"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.TransformerEncoderLayer.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">return_attn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward pass in the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: input tensor.</span>
<span class="sd">            mask: mask to apply in the attention layer.</span>
<span class="sd">            return_attn: whether to return the attention together with the output.</span>
<span class="sd">                Defaults to False, return only encoder output.</span>

<span class="sd">        Returns:</span>
<span class="sd">            model output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">return_attn</span><span class="p">:</span>
            <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">return_attn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sublayer</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span>  <span class="c1"># type:ignore</span>
                <span class="n">x</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sublayer</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward</span><span class="p">),</span> <span class="n">attn</span>  <span class="c1"># type:ignore</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sublayer</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span>  <span class="c1"># type:ignore</span>
                <span class="n">x</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sublayer</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward</span><span class="p">)</span>  <span class="c1"># type:ignore</span></div></div>


<div class="viewcode-block" id="TransformerDecoder"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.TransformerDecoder">[docs]</a><span class="k">class</span> <span class="nc">TransformerDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base transformer decoder architecture.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="TransformerDecoder.__init__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.TransformerDecoder.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">ff_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">n_layers_dec</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">latent_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">bypass_bottleneck</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">deconv_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Construct TransformerDecoder.</span>

<span class="sd">        Args:</span>
<span class="sd">            hidden_size: hidden size.</span>
<span class="sd">            ff_size: feed forward size.</span>
<span class="sd">            seq_len: sequence length.</span>
<span class="sd">            dropout: dropout rate.</span>
<span class="sd">            heads: number of heads.</span>
<span class="sd">            n_layers_enc: number of encoding layers.</span>
<span class="sd">            latent_size: latent size.</span>
<span class="sd">            vocab_size: vocabulary size.</span>
<span class="sd">            bypass_bottleneck: whether the bottleneck should be by passed.</span>
<span class="sd">            deconv_shape: shape of the deconvoluted samples. A tuple with three</span>
<span class="sd">                dimensions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">position</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">Embeddings</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">position</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_enc</span> <span class="o">=</span> <span class="n">MultiHeadedAttention</span><span class="p">(</span><span class="n">heads</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ff_enc</span> <span class="o">=</span> <span class="n">PositionwiseFeedForward</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">ff_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_dec_1</span> <span class="o">=</span> <span class="n">MultiHeadedAttention</span><span class="p">(</span><span class="n">heads</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_dec_2</span> <span class="o">=</span> <span class="n">MultiHeadedAttention</span><span class="p">(</span><span class="n">heads</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">ff_dec</span> <span class="o">=</span> <span class="n">PositionwiseFeedForward</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">ff_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>

        <span class="n">encoder_layers</span> <span class="o">=</span> <span class="n">TransformerEncoderLayer</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_enc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff_enc</span><span class="p">,</span> <span class="n">dropout</span>
        <span class="p">)</span>
        <span class="n">decoder_layers</span> <span class="o">=</span> <span class="n">TransformerDecoderLayer</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">seq_len</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attn_dec_1</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attn_dec_2</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ff_dec</span><span class="p">,</span>
            <span class="n">dropout</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">final_encodes</span> <span class="o">=</span> <span class="n">clones</span><span class="p">(</span><span class="n">encoder_layers</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">clones</span><span class="p">(</span><span class="n">decoder_layers</span><span class="p">,</span> <span class="n">n_layers_dec</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bypass_bottleneck</span> <span class="o">=</span> <span class="n">bypass_bottleneck</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">seq_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs2vocab</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">deconv_shape</span> <span class="o">=</span> <span class="n">deconv_shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">deconv_bottleneck</span> <span class="o">=</span> <span class="n">DeconvBottleneck</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">dim_factor</span><span class="o">=</span><span class="n">deconv_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_size</span><span class="p">,</span> <span class="n">deconv_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">deconv_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span></div>

<div class="viewcode-block" id="TransformerDecoder.forward"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.TransformerDecoder.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">mem</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">src_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">tgt_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward pass in the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: input tensor.</span>
<span class="sd">            mem: memory tensor.</span>
<span class="sd">            src_mask: source sequence mask.</span>
<span class="sd">            tgt_mask: target sequence mask.</span>

<span class="sd">        Returns:</span>
<span class="sd">            model output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">bypass_bottleneck</span><span class="p">:</span>
            <span class="n">mem</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">mem</span><span class="p">))</span>
            <span class="n">mem</span> <span class="o">=</span> <span class="n">mem</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">deconv_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
            <span class="n">mem</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">deconv_bottleneck</span><span class="p">(</span><span class="n">mem</span><span class="p">)</span>
            <span class="n">mem</span> <span class="o">=</span> <span class="n">mem</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">final_encode</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_encodes</span><span class="p">:</span>  <span class="c1"># type:ignore</span>
            <span class="n">mem</span> <span class="o">=</span> <span class="n">final_encode</span><span class="p">(</span><span class="n">mem</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">)</span>
        <span class="n">mem</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">mem</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">attn_layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>  <span class="c1"># type:ignore</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">attn_layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mem</span><span class="p">,</span> <span class="n">mem</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs2vocab</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span></div>

<div class="viewcode-block" id="TransformerDecoder.inference_direct"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.TransformerDecoder.inference_direct">[docs]</a>    <span class="k">def</span> <span class="nf">inference_direct</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">latent</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">mask_lengths</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Tokenizer</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Direct inference from latent space.</span>

<span class="sd">        Args:</span>
<span class="sd">            latent: latent tensor.</span>
<span class="sd">            mask_lengths: masking tensor.</span>
<span class="sd">            tokenizer: tokenizer.</span>

<span class="sd">        Returns:</span>
<span class="sd">            a tuple containing decoded strings and indices.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">get_device_from_tensor</span><span class="p">(</span><span class="n">latent</span><span class="p">)</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">latent</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">token_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
            <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">sos_token_id</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
        <span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

        <span class="n">src_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">latent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mask_lengths</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">mask_len</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">mask_lengths</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">src_mask</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">mask_len</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">mask_len</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">trg_mask</span> <span class="o">=</span> <span class="n">subsequent_mask</span><span class="p">(</span><span class="n">token_indices</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">token_indices</span><span class="p">),</span> <span class="n">latent</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> <span class="n">trg_mask</span>
            <span class="p">)</span>

            <span class="n">prob</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">next_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">prob</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">next_token</span> <span class="o">=</span> <span class="n">next_token</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">token_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">token_indices</span><span class="p">,</span> <span class="n">next_token</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">decoded_texts</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_id_to_token</span><span class="p">(</span><span class="n">vocab_index</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                <span class="k">for</span> <span class="n">vocab_index</span> <span class="ow">in</span> <span class="n">token_indices</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
            <span class="p">]</span>
            <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">decoded_texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">decoded_texts</span><span class="p">,</span> <span class="n">token_indices</span></div></div>


<div class="viewcode-block" id="TransformerDecoderLayer"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.TransformerDecoderLayer">[docs]</a><span class="k">class</span> <span class="nc">TransformerDecoderLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Self-attention/source-attention/feedforward implementation.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="TransformerDecoderLayer.__init__"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.TransformerDecoderLayer.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">self_attn</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">src_attn</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">feed_forward</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Construct TransformerDecoderLayer.</span>

<span class="sd">        Args:</span>
<span class="sd">            size: model size.</span>
<span class="sd">            seq_len: sequence length.</span>
<span class="sd">            self_attn: self-attention layer.</span>
<span class="sd">            src_attn: source attention layer.</span>
<span class="sd">            feed_forward: feed forward layer.</span>
<span class="sd">            dropout: droupout rate.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tgt_len</span> <span class="o">=</span> <span class="n">seq_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span> <span class="o">=</span> <span class="n">self_attn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">src_attn</span> <span class="o">=</span> <span class="n">src_attn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward</span> <span class="o">=</span> <span class="n">feed_forward</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sublayer</span> <span class="o">=</span> <span class="n">clones</span><span class="p">(</span><span class="n">SublayerConnection</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span></div>

<div class="viewcode-block" id="TransformerDecoderLayer.forward"><a class="viewcode-back" href="../../../../../../api/gt4sd.frameworks.granular.ml.models.module.html#gt4sd.frameworks.granular.ml.models.module.TransformerDecoderLayer.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">memory_key</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">memory_val</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">src_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">tgt_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">return_attn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward pass in the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: input tensor</span>
<span class="sd">            memory_key: memory key tensor.</span>
<span class="sd">            memory_val: memory value tensor.s</span>
<span class="sd">            src_mask: mask to apply in the source attention layer.</span>
<span class="sd">            tgt_mask: mask to apply in the target attention layer.</span>
<span class="sd">            return_attn: whether to return the attention together with the output.</span>
<span class="sd">                Defaults to False, return only encoder output.</span>

<span class="sd">        Returns:</span>
<span class="sd">            model output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">m_key</span> <span class="o">=</span> <span class="n">memory_key</span>
        <span class="n">m_val</span> <span class="o">=</span> <span class="n">memory_val</span>
        <span class="k">if</span> <span class="n">return_attn</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sublayer</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span>  <span class="c1"># type:ignore</span>
                <span class="n">x</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">src_attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">src_attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">m_key</span><span class="p">,</span> <span class="n">m_val</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> <span class="n">return_attn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sublayer</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span>  <span class="c1"># type:ignore</span>
                <span class="n">x</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">src_attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">m_key</span><span class="p">,</span> <span class="n">m_val</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sublayer</span><span class="p">[</span><span class="mi">2</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward</span><span class="p">),</span> <span class="n">src_attn</span>  <span class="c1"># type:ignore</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sublayer</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span>  <span class="c1"># type:ignore</span>
                <span class="n">x</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sublayer</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span>  <span class="c1"># type:ignore</span>
                <span class="n">x</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">src_attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">m_key</span><span class="p">,</span> <span class="n">m_val</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sublayer</span><span class="p">[</span><span class="mi">2</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward</span><span class="p">)</span>  <span class="c1"># type:ignore</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright GT4SD team 2022.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>