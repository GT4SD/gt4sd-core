

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>gt4sd.training_pipelines.regression_transformer.utils module &mdash; gt4sd  documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="gt4sd.training_pipelines.tests package" href="gt4sd.training_pipelines.tests.html" />
    <link rel="prev" title="gt4sd.training_pipelines.regression_transformer.implementation module" href="gt4sd.training_pipelines.regression_transformer.implementation.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> gt4sd
          

          
            
            <img src="../_static/gt4sd_logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../source/gt4sd_inference_usage_md.html">Examples on how to use the GT4SD algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../source/gt4sd_algorithm_addition_md.html">Examples on how to add an algorithm to GT4SD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../source/gt4sd_server_upload_md.html">Examples on how to upload models on a self-hosted minio service using GT4SD</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="gt4sd.html">API of the gt4sd package</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="gt4sd.configuration.html">gt4sd.configuration module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gt4sd.conftest.html">gt4sd.conftest module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gt4sd.exceptions.html">gt4sd.exceptions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gt4sd.s3.html">gt4sd.s3 module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gt4sd.algorithms.html">gt4sd.algorithms package</a></li>
<li class="toctree-l2"><a class="reference internal" href="gt4sd.cli.html">gt4sd.cli package</a></li>
<li class="toctree-l2"><a class="reference internal" href="gt4sd.domains.html">gt4sd.domains package</a></li>
<li class="toctree-l2"><a class="reference internal" href="gt4sd.extras.html">gt4sd.extras package</a></li>
<li class="toctree-l2"><a class="reference internal" href="gt4sd.frameworks.html">gt4sd.frameworks package</a></li>
<li class="toctree-l2"><a class="reference internal" href="gt4sd.tests.html">gt4sd.tests package</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="gt4sd.training_pipelines.html">gt4sd.training_pipelines package</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="gt4sd.training_pipelines.core.html">gt4sd.training_pipelines.core module</a></li>
<li class="toctree-l3"><a class="reference internal" href="gt4sd.training_pipelines.guacamol_baselines.html">gt4sd.training_pipelines.guacamol_baselines package</a></li>
<li class="toctree-l3"><a class="reference internal" href="gt4sd.training_pipelines.moses.html">gt4sd.training_pipelines.moses package</a></li>
<li class="toctree-l3"><a class="reference internal" href="gt4sd.training_pipelines.paccmann.html">gt4sd.training_pipelines.paccmann package</a></li>
<li class="toctree-l3"><a class="reference internal" href="gt4sd.training_pipelines.pytorch_lightning.html">gt4sd.training_pipelines.pytorch_lightning package</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="gt4sd.training_pipelines.regression_transformer.html">gt4sd.training_pipelines.regression_transformer package</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="gt4sd.training_pipelines.regression_transformer.core.html">gt4sd.training_pipelines.regression_transformer.core module</a></li>
<li class="toctree-l4"><a class="reference internal" href="gt4sd.training_pipelines.regression_transformer.implementation.html">gt4sd.training_pipelines.regression_transformer.implementation module</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">gt4sd.training_pipelines.regression_transformer.utils module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="gt4sd.training_pipelines.tests.html">gt4sd.training_pipelines.tests package</a></li>
<li class="toctree-l3"><a class="reference internal" href="gt4sd.training_pipelines.torchdrug.html">gt4sd.training_pipelines.torchdrug package</a></li>
<li class="toctree-l3"><a class="reference internal" href="gt4sd.training_pipelines.html#summary">Summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="gt4sd.training_pipelines.html#reference">Reference</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">gt4sd</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="gt4sd.html">gt4sd package</a> &raquo;</li>
        
          <li><a href="gt4sd.training_pipelines.html">gt4sd.training_pipelines package</a> &raquo;</li>
        
          <li><a href="gt4sd.training_pipelines.regression_transformer.html">gt4sd.training_pipelines.regression_transformer package</a> &raquo;</li>
        
      <li>gt4sd.training_pipelines.regression_transformer.utils module</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/api/gt4sd.training_pipelines.regression_transformer.utils.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="module-gt4sd.training_pipelines.regression_transformer.utils">
<span id="gt4sd-training-pipelines-regression-transformer-utils-module"></span><h1>gt4sd.training_pipelines.regression_transformer.utils module<a class="headerlink" href="#module-gt4sd.training_pipelines.regression_transformer.utils" title="Permalink to this headline">¶</a></h1>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>Classes:</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI" title="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TransformersTrainingArgumentsCLI</span></code></a></p></td>
<td><p>GT4SD ships with a CLI to launch training.</p></td>
</tr>
</tbody>
</table>
<p>Functions:</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#gt4sd.training_pipelines.regression_transformer.utils.add_tokens_from_lists" title="gt4sd.training_pipelines.regression_transformer.utils.add_tokens_from_lists"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_tokens_from_lists</span></code></a></p></td>
<td><p>Addding tokens to a tokenizer from parsed datasets hold in memory.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#gt4sd.training_pipelines.regression_transformer.utils.get_hf_training_arg_object" title="gt4sd.training_pipelines.regression_transformer.utils.get_hf_training_arg_object"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_hf_training_arg_object</span></code></a></p></td>
<td><p>A method to convert a training_args Dictionary into a HuggingFace <cite>TrainingArguments</cite> object.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#gt4sd.training_pipelines.regression_transformer.utils.get_train_config_dict" title="gt4sd.training_pipelines.regression_transformer.utils.get_train_config_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_train_config_dict</span></code></a></p></td>
<td><p><dl class="field-list simple">
<dt class="field-odd">rtype</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]</p>
</dd>
</dl>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#gt4sd.training_pipelines.regression_transformer.utils.prepare_datasets_from_files" title="gt4sd.training_pipelines.regression_transformer.utils.prepare_datasets_from_files"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prepare_datasets_from_files</span></code></a></p></td>
<td><p>Converts datasets saved in provided <cite>.csv</cite> paths into RT-compatible datasets.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.add_tokens_from_lists">
<code class="sig-name descname">add_tokens_from_lists</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokenizer</span></em>, <em class="sig-param"><span class="n">train_data</span></em>, <em class="sig-param"><span class="n">test_data</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/training_pipelines/regression_transformer/utils.html#add_tokens_from_lists"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.add_tokens_from_lists" title="Permalink to this definition">¶</a></dt>
<dd><p>Addding tokens to a tokenizer from parsed datasets hold in memory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tokenizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">ExpressionBertTokenizer</span></code>) – The tokenizer.</p></li>
<li><p><strong>train_data</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – List of strings, one per sample.</p></li>
<li><p><strong>test_data</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – List of strings, one per sample.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tokenizer with updated vocabulary.
set of property tokens.
list of strings with training samples.
list of strings with testing samples.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple with</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.prepare_datasets_from_files">
<code class="sig-name descname">prepare_datasets_from_files</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokenizer</span></em>, <em class="sig-param"><span class="n">train_path</span></em>, <em class="sig-param"><span class="n">test_path</span></em>, <em class="sig-param"><span class="n">augment</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/training_pipelines/regression_transformer/utils.html#prepare_datasets_from_files"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.prepare_datasets_from_files" title="Permalink to this definition">¶</a></dt>
<dd><p>Converts datasets saved in provided <cite>.csv</cite> paths into RT-compatible datasets.
NOTE: Also adds the new tokens from train/test data to provided tokenizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tokenizer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">ExpressionBertTokenizer</span></code>) – The tokenizer.</p></li>
<li><p><strong>train_path</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Path to the training data.</p></li>
<li><p><strong>test_path</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Path to the testing data.</p></li>
<li><p><strong>augment</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Factor by which each training sample is augmented.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tokenizer with updated vocabulary.
set of property tokens.
list of strings with training samples.
list of strings with testing samples.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple with</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.get_train_config_dict">
<code class="sig-name descname">get_train_config_dict</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">training_args</span></em>, <em class="sig-param"><span class="n">properties</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/training_pipelines/regression_transformer/utils.html#get_train_config_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.get_train_config_dict" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI">
<em class="property">class </em><code class="sig-name descname">TransformersTrainingArgumentsCLI</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">output_dir</span></em>, <em class="sig-param"><span class="n">overwrite_output_dir</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">do_train</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">do_eval</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">do_predict</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">evaluation_strategy</span><span class="o">=</span><span class="default_value">'no'</span></em>, <em class="sig-param"><span class="n">prediction_loss_only</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="default_value">8</span></em>, <em class="sig-param"><span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="default_value">8</span></em>, <em class="sig-param"><span class="n">per_gpu_train_batch_size</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">per_gpu_eval_batch_size</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">eval_accumulation_steps</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">eval_delay</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">learning_rate</span><span class="o">=</span><span class="default_value">5e-05</span></em>, <em class="sig-param"><span class="n">weight_decay</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">adam_beta1</span><span class="o">=</span><span class="default_value">0.9</span></em>, <em class="sig-param"><span class="n">adam_beta2</span><span class="o">=</span><span class="default_value">0.999</span></em>, <em class="sig-param"><span class="n">adam_epsilon</span><span class="o">=</span><span class="default_value">1e-08</span></em>, <em class="sig-param"><span class="n">max_grad_norm</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">num_train_epochs</span><span class="o">=</span><span class="default_value">3.0</span></em>, <em class="sig-param"><span class="n">max_steps</span><span class="o">=</span><span class="default_value">- 1</span></em>, <em class="sig-param"><span class="n">lr_scheduler_type</span><span class="o">=</span><span class="default_value">'linear'</span></em>, <em class="sig-param"><span class="n">warmup_ratio</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">warmup_steps</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">log_level</span><span class="o">=</span><span class="default_value">'passive'</span></em>, <em class="sig-param"><span class="n">log_level_replica</span><span class="o">=</span><span class="default_value">'passive'</span></em>, <em class="sig-param"><span class="n">log_on_each_node</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">logging_dir</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">logging_strategy</span><span class="o">=</span><span class="default_value">'steps'</span></em>, <em class="sig-param"><span class="n">logging_first_step</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">logging_steps</span><span class="o">=</span><span class="default_value">500</span></em>, <em class="sig-param"><span class="n">logging_nan_inf_filter</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">save_strategy</span><span class="o">=</span><span class="default_value">'steps'</span></em>, <em class="sig-param"><span class="n">save_steps</span><span class="o">=</span><span class="default_value">500</span></em>, <em class="sig-param"><span class="n">save_total_limit</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">save_on_each_node</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">no_cuda</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">seed</span><span class="o">=</span><span class="default_value">42</span></em>, <em class="sig-param"><span class="n">data_seed</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">jit_mode_eval</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">use_ipex</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">bf16</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">fp16</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">fp16_opt_level</span><span class="o">=</span><span class="default_value">'O1'</span></em>, <em class="sig-param"><span class="n">half_precision_backend</span><span class="o">=</span><span class="default_value">'auto'</span></em>, <em class="sig-param"><span class="n">bf16_full_eval</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">fp16_full_eval</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">tf32</span><span class="o">=</span><span class="default_value">'no'</span></em>, <em class="sig-param"><span class="n">local_rank</span><span class="o">=</span><span class="default_value">- 1</span></em>, <em class="sig-param"><span class="n">xpu_backend</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">tpu_num_cores</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">tpu_metrics_debug</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">debug</span><span class="o">=</span><span class="default_value">''</span></em>, <em class="sig-param"><span class="n">dataloader_drop_last</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">eval_steps</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">dataloader_num_workers</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">past_index</span><span class="o">=</span><span class="default_value">- 1</span></em>, <em class="sig-param"><span class="n">run_name</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">disable_tqdm</span><span class="o">=</span><span class="default_value">'no'</span></em>, <em class="sig-param"><span class="n">remove_unused_columns</span><span class="o">=</span><span class="default_value">'yes'</span></em>, <em class="sig-param"><span class="n">label_names</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">load_best_model_at_end</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">metric_for_best_model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">greater_is_better</span><span class="o">=</span><span class="default_value">'no'</span></em>, <em class="sig-param"><span class="n">ignore_data_skip</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">sharded_ddp</span><span class="o">=</span><span class="default_value">''</span></em>, <em class="sig-param"><span class="n">fsdp</span><span class="o">=</span><span class="default_value">''</span></em>, <em class="sig-param"><span class="n">fsdp_min_num_params</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">deepspeed</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">label_smoothing_factor</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">optim</span><span class="o">=</span><span class="default_value">'adamw_hf'</span></em>, <em class="sig-param"><span class="n">adafactor</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">group_by_length</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">length_column_name</span><span class="o">=</span><span class="default_value">'length'</span></em>, <em class="sig-param"><span class="n">report_to</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ddp_find_unused_parameters</span><span class="o">=</span><span class="default_value">'no'</span></em>, <em class="sig-param"><span class="n">ddp_bucket_cap_mb</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">dataloader_pin_memory</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">skip_memory_metrics</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">use_legacy_prediction_loop</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">push_to_hub</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">resume_from_checkpoint</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">hub_model_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">hub_strategy</span><span class="o">=</span><span class="default_value">'every_save'</span></em>, <em class="sig-param"><span class="n">hub_token</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">hub_private_repo</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">gradient_checkpointing</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">include_inputs_for_metrics</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">fp16_backend</span><span class="o">=</span><span class="default_value">'auto'</span></em>, <em class="sig-param"><span class="n">push_to_hub_model_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">push_to_hub_organization</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">push_to_hub_token</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">mp_parameters</span><span class="o">=</span><span class="default_value">''</span></em>, <em class="sig-param"><span class="n">auto_find_batch_size</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">full_determinism</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">torchdynamo</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ray_scope</span><span class="o">=</span><span class="default_value">'last'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/training_pipelines/regression_transformer/utils.html#TransformersTrainingArgumentsCLI"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.training_args.TrainingArguments</span></code></p>
<p>GT4SD ships with a CLI to launch training. This conflicts with some data types
native in <cite>transformers.training_arguments.TrainingArguments</cite> especially iterables
which cannot be easily passed from CLI.
Therefore, this class changes the affected attributes to CLI compatible datatypes.</p>
<dl class="py attribute">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.label_names">
<code class="sig-name descname">label_names</code><em class="property">: Optional<span class="p">[</span>str<span class="p">]</span></em><em class="property"> = None</em><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.label_names" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.report_to">
<code class="sig-name descname">report_to</code><em class="property">: Optional<span class="p">[</span>str<span class="p">]</span></em><em class="property"> = None</em><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.report_to" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.sharded_ddp">
<code class="sig-name descname">sharded_ddp</code><em class="property">: str</em><em class="property"> = ''</em><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.sharded_ddp" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.tf32">
<code class="sig-name descname">tf32</code><em class="property">: Optional<span class="p">[</span>str<span class="p">]</span></em><em class="property"> = 'no'</em><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.tf32" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.disable_tqdm">
<code class="sig-name descname">disable_tqdm</code><em class="property">: Optional<span class="p">[</span>str<span class="p">]</span></em><em class="property"> = 'no'</em><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.disable_tqdm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.greater_is_better">
<code class="sig-name descname">greater_is_better</code><em class="property">: Optional<span class="p">[</span>str<span class="p">]</span></em><em class="property"> = 'no'</em><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.greater_is_better" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.remove_unused_columns">
<code class="sig-name descname">remove_unused_columns</code><em class="property">: Optional<span class="p">[</span>str<span class="p">]</span></em><em class="property"> = 'yes'</em><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.remove_unused_columns" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.load_best_model_at_end">
<code class="sig-name descname">load_best_model_at_end</code><em class="property">: Optional<span class="p">[</span>str<span class="p">]</span></em><em class="property"> = None</em><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.load_best_model_at_end" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.ddp_find_unused_parameters">
<code class="sig-name descname">ddp_find_unused_parameters</code><em class="property">: Optional<span class="p">[</span>str<span class="p">]</span></em><em class="property"> = 'no'</em><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.ddp_find_unused_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__post_init__">
<code class="sig-name descname">__post_init__</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/training_pipelines/regression_transformer/utils.html#TransformersTrainingArgumentsCLI.__post_init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__post_init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Necessary because the our ArgumentParser (that is based on argparse) converts
empty strings to None. This is prohibitive since the HFTrainer relies on
them being actual strings. Only concerns a few arguments.</p>
</dd></dl>

<dl class="py attribute">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__annotations__">
<code class="sig-name descname">__annotations__</code><em class="property"> = {'_n_gpu': 'int', 'adafactor': 'bool', 'adam_beta1': 'float', 'adam_beta2': 'float', 'adam_epsilon': 'float', 'auto_find_batch_size': 'bool', 'bf16': 'bool', 'bf16_full_eval': 'bool', 'data_seed': 'Optional[int]', 'dataloader_drop_last': 'bool', 'dataloader_num_workers': 'int', 'dataloader_pin_memory': 'bool', 'ddp_bucket_cap_mb': 'Optional[int]', 'ddp_find_unused_parameters': typing.Union[str, NoneType], 'debug': 'str', 'deepspeed': 'Optional[str]', 'disable_tqdm': typing.Union[str, NoneType], 'do_eval': 'bool', 'do_predict': 'bool', 'do_train': 'bool', 'eval_accumulation_steps': 'Optional[int]', 'eval_delay': 'Optional[float]', 'eval_steps': 'Optional[int]', 'evaluation_strategy': 'IntervalStrategy', 'fp16': 'bool', 'fp16_backend': 'str', 'fp16_full_eval': 'bool', 'fp16_opt_level': 'str', 'fsdp': 'str', 'fsdp_min_num_params': 'int', 'full_determinism': 'bool', 'gradient_accumulation_steps': 'int', 'gradient_checkpointing': 'bool', 'greater_is_better': typing.Union[str, NoneType], 'group_by_length': 'bool', 'half_precision_backend': 'str', 'hub_model_id': 'Optional[str]', 'hub_private_repo': 'bool', 'hub_strategy': 'HubStrategy', 'hub_token': 'Optional[str]', 'ignore_data_skip': 'bool', 'include_inputs_for_metrics': 'bool', 'jit_mode_eval': 'bool', 'label_names': typing.Union[str, NoneType], 'label_smoothing_factor': 'float', 'learning_rate': 'float', 'length_column_name': 'Optional[str]', 'load_best_model_at_end': typing.Union[str, NoneType], 'local_rank': 'int', 'log_level': 'Optional[str]', 'log_level_replica': 'Optional[str]', 'log_on_each_node': 'bool', 'logging_dir': 'Optional[str]', 'logging_first_step': 'bool', 'logging_nan_inf_filter': 'bool', 'logging_steps': 'int', 'logging_strategy': 'IntervalStrategy', 'lr_scheduler_type': 'SchedulerType', 'max_grad_norm': 'float', 'max_steps': 'int', 'metric_for_best_model': 'Optional[str]', 'mp_parameters': 'str', 'no_cuda': 'bool', 'num_train_epochs': 'float', 'optim': 'OptimizerNames', 'output_dir': 'str', 'overwrite_output_dir': 'bool', 'past_index': 'int', 'per_device_eval_batch_size': 'int', 'per_device_train_batch_size': 'int', 'per_gpu_eval_batch_size': 'Optional[int]', 'per_gpu_train_batch_size': 'Optional[int]', 'prediction_loss_only': 'bool', 'push_to_hub': 'bool', 'push_to_hub_model_id': 'Optional[str]', 'push_to_hub_organization': 'Optional[str]', 'push_to_hub_token': 'Optional[str]', 'ray_scope': 'Optional[str]', 'remove_unused_columns': typing.Union[str, NoneType], 'report_to': typing.Union[str, NoneType], 'resume_from_checkpoint': 'Optional[str]', 'run_name': 'Optional[str]', 'save_on_each_node': 'bool', 'save_steps': 'int', 'save_strategy': 'IntervalStrategy', 'save_total_limit': 'Optional[int]', 'seed': 'int', 'sharded_ddp': &lt;class 'str'&gt;, 'skip_memory_metrics': 'bool', 'tf32': typing.Union[str, NoneType], 'torchdynamo': 'Optional[str]', 'tpu_metrics_debug': 'bool', 'tpu_num_cores': 'Optional[int]', 'use_ipex': 'bool', 'use_legacy_prediction_loop': 'bool', 'warmup_ratio': 'float', 'warmup_steps': 'int', 'weight_decay': 'float', 'xpu_backend': 'Optional[str]'}</em><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__annotations__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__dataclass_fields__">
<code class="sig-name descname">__dataclass_fields__</code><em class="property"> = {'_n_gpu': Field(name='_n_gpu',type=&lt;class 'int'&gt;,default=-1,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=False,repr=False,hash=None,compare=True,metadata=mappingproxy({}),_field_type=_FIELD), 'adafactor': Field(name='adafactor',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether or not to replace AdamW by Adafactor.'}),_field_type=_FIELD), 'adam_beta1': Field(name='adam_beta1',type=&lt;class 'float'&gt;,default=0.9,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Beta1 for AdamW optimizer'}),_field_type=_FIELD), 'adam_beta2': Field(name='adam_beta2',type=&lt;class 'float'&gt;,default=0.999,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Beta2 for AdamW optimizer'}),_field_type=_FIELD), 'adam_epsilon': Field(name='adam_epsilon',type=&lt;class 'float'&gt;,default=1e-08,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Epsilon for AdamW optimizer.'}),_field_type=_FIELD), 'auto_find_batch_size': Field(name='auto_find_batch_size',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether to automatically decrease the batch size in half and rerun the training loop again each time a CUDA Out-of-Memory was reached'}),_field_type=_FIELD), 'bf16': Field(name='bf16',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether to use bf16 (mixed) precision instead of 32-bit. Requires Ampere or higher NVIDIA architecture or using CPU (no_cuda). This is an experimental API and it may change.'}),_field_type=_FIELD), 'bf16_full_eval': Field(name='bf16_full_eval',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether to use full bfloat16 evaluation instead of 32-bit. This is an experimental API and it may change.'}),_field_type=_FIELD), 'data_seed': Field(name='data_seed',type=typing.Union[int, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Random seed to be used with data samplers.'}),_field_type=_FIELD), 'dataloader_drop_last': Field(name='dataloader_drop_last',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Drop the last incomplete batch if it is not divisible by the batch size.'}),_field_type=_FIELD), 'dataloader_num_workers': Field(name='dataloader_num_workers',type=&lt;class 'int'&gt;,default=0,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Number of subprocesses to use for data loading (PyTorch only). 0 means that the data will be loaded in the main process.'}),_field_type=_FIELD), 'dataloader_pin_memory': Field(name='dataloader_pin_memory',type=&lt;class 'bool'&gt;,default=True,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether or not to pin memory for DataLoader.'}),_field_type=_FIELD), 'ddp_bucket_cap_mb': Field(name='ddp_bucket_cap_mb',type=typing.Union[int, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'When using distributed training, the value of the flag `bucket_cap_mb` passed to `DistributedDataParallel`.'}),_field_type=_FIELD), 'ddp_find_unused_parameters': Field(name='ddp_find_unused_parameters',type=typing.Union[str, NoneType],default='no',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'When using distributed training, the value of the flag `find_unused_parameters` passed to `DistributedDataParallel`.'}),_field_type=_FIELD), 'debug': Field(name='debug',type=&lt;class 'str'&gt;,default='',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether or not to enable debug mode. Current options: `underflow_overflow` (Detect underflow and overflow in activations and weights), `tpu_metrics_debug` (print debug metrics on TPU).'}),_field_type=_FIELD), 'deepspeed': Field(name='deepspeed',type=typing.Union[str, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Enable deepspeed and pass the path to deepspeed json config file (e.g. ds_config.json) or an already loaded json file as a dict'}),_field_type=_FIELD), 'disable_tqdm': Field(name='disable_tqdm',type=typing.Union[str, NoneType],default='no',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether or not to disable the tqdm progress bars.'}),_field_type=_FIELD), 'do_eval': Field(name='do_eval',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether to run eval on the dev set.'}),_field_type=_FIELD), 'do_predict': Field(name='do_predict',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether to run predictions on the test set.'}),_field_type=_FIELD), 'do_train': Field(name='do_train',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether to run training.'}),_field_type=_FIELD), 'eval_accumulation_steps': Field(name='eval_accumulation_steps',type=typing.Union[int, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Number of predictions steps to accumulate before moving the tensors to the CPU.'}),_field_type=_FIELD), 'eval_delay': Field(name='eval_delay',type=typing.Union[float, NoneType],default=0,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Number of epochs or steps to wait for before the first evaluation can be performed, depending on the evaluation_strategy.'}),_field_type=_FIELD), 'eval_steps': Field(name='eval_steps',type=typing.Union[int, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Run an evaluation every X steps.'}),_field_type=_FIELD), 'evaluation_strategy': Field(name='evaluation_strategy',type=&lt;enum 'IntervalStrategy'&gt;,default='no',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The evaluation strategy to use.'}),_field_type=_FIELD), 'fp16': Field(name='fp16',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether to use fp16 (mixed) precision instead of 32-bit'}),_field_type=_FIELD), 'fp16_backend': Field(name='fp16_backend',type=&lt;class 'str'&gt;,default='auto',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Deprecated. Use half_precision_backend instead', 'choices': ['auto', 'cuda_amp', 'apex', 'cpu_amp']}),_field_type=_FIELD), 'fp16_full_eval': Field(name='fp16_full_eval',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether to use full float16 evaluation instead of 32-bit'}),_field_type=_FIELD), 'fp16_opt_level': Field(name='fp16_opt_level',type=&lt;class 'str'&gt;,default='O1',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': &quot;For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3']. See details at https://nvidia.github.io/apex/amp.html&quot;}),_field_type=_FIELD), 'fsdp': Field(name='fsdp',type=&lt;class 'str'&gt;,default='',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether or not to use PyTorch Fully Sharded Data Parallel (FSDP) training (in distributed training only). The base option should be `full_shard` or `shard_grad_op` and you can add CPU-offload to `full_shard` or `shard_grad_op` like this: full_shard offload` or `shard_grad_op offload`. You can add auto-wrap to `full_shard` or `shard_grad_op` with the same syntax: full_shard auto_wrap` or `shard_grad_op auto_wrap`.'}),_field_type=_FIELD), 'fsdp_min_num_params': Field(name='fsdp_min_num_params',type=&lt;class 'int'&gt;,default=0,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': &quot;FSDP's minimum number of parameters for Default Auto Wrapping. (useful only when `fsdp` field is passed).&quot;}),_field_type=_FIELD), 'full_determinism': Field(name='full_determinism',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether to call enable_full_determinism instead of set_seed for reproducibility in distributed training'}),_field_type=_FIELD), 'gradient_accumulation_steps': Field(name='gradient_accumulation_steps',type=&lt;class 'int'&gt;,default=1,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Number of updates steps to accumulate before performing a backward/update pass.'}),_field_type=_FIELD), 'gradient_checkpointing': Field(name='gradient_checkpointing',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'If True, use gradient checkpointing to save memory at the expense of slower backward pass.'}),_field_type=_FIELD), 'greater_is_better': Field(name='greater_is_better',type=typing.Union[str, NoneType],default='no',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether the `metric_for_best_model` should be maximized or not.'}),_field_type=_FIELD), 'group_by_length': Field(name='group_by_length',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether or not to group samples of roughly the same length together when batching.'}),_field_type=_FIELD), 'half_precision_backend': Field(name='half_precision_backend',type=&lt;class 'str'&gt;,default='auto',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The backend to be used for half precision.', 'choices': ['auto', 'cuda_amp', 'apex', 'cpu_amp']}),_field_type=_FIELD), 'hub_model_id': Field(name='hub_model_id',type=typing.Union[str, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The name of the repository to keep in sync with the local `output_dir`.'}),_field_type=_FIELD), 'hub_private_repo': Field(name='hub_private_repo',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether the model repository is private or not.'}),_field_type=_FIELD), 'hub_strategy': Field(name='hub_strategy',type=&lt;enum 'HubStrategy'&gt;,default='every_save',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The hub strategy to use when `--push_to_hub` is activated.'}),_field_type=_FIELD), 'hub_token': Field(name='hub_token',type=typing.Union[str, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The token to use to push to the Model Hub.'}),_field_type=_FIELD), 'ignore_data_skip': Field(name='ignore_data_skip',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'When resuming training, whether or not to skip the first epochs and batches to get to the same training data.'}),_field_type=_FIELD), 'include_inputs_for_metrics': Field(name='include_inputs_for_metrics',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether or not the inputs will be passed to the `compute_metrics` function.'}),_field_type=_FIELD), 'jit_mode_eval': Field(name='jit_mode_eval',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether or not to use PyTorch jit trace for inference'}),_field_type=_FIELD), 'label_names': Field(name='label_names',type=typing.Union[str, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'A string containing keys in your dictionary of inputs that correspond to the labels.A single string, but can contain multiple keys separated with comma: `key1,key2`'}),_field_type=_FIELD), 'label_smoothing_factor': Field(name='label_smoothing_factor',type=&lt;class 'float'&gt;,default=0.0,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The label smoothing epsilon to apply (zero means no label smoothing).'}),_field_type=_FIELD), 'learning_rate': Field(name='learning_rate',type=&lt;class 'float'&gt;,default=5e-05,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The initial learning rate for AdamW.'}),_field_type=_FIELD), 'length_column_name': Field(name='length_column_name',type=typing.Union[str, NoneType],default='length',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Column name with precomputed lengths to use when grouping by length.'}),_field_type=_FIELD), 'load_best_model_at_end': Field(name='load_best_model_at_end',type=typing.Union[str, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether or not to load the best model found during training at the end of training.'}),_field_type=_FIELD), 'local_rank': Field(name='local_rank',type=&lt;class 'int'&gt;,default=-1,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'For distributed training: local_rank'}),_field_type=_FIELD), 'log_level': Field(name='log_level',type=typing.Union[str, NoneType],default='passive',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': &quot;Logger log level to use on the main node. Possible choices are the log levels as strings: 'debug', 'info', 'warning', 'error' and 'critical', plus a 'passive' level which doesn't set anything and lets the application set the level. Defaults to 'passive'.&quot;, 'choices': dict_keys(['debug', 'info', 'warning', 'error', 'critical', 'passive'])}),_field_type=_FIELD), 'log_level_replica': Field(name='log_level_replica',type=typing.Union[str, NoneType],default='passive',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Logger log level to use on replica nodes. Same choices and defaults as ``log_level``', 'choices': dict_keys(['debug', 'info', 'warning', 'error', 'critical', 'passive'])}),_field_type=_FIELD), 'log_on_each_node': Field(name='log_on_each_node',type=&lt;class 'bool'&gt;,default=True,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'When doing a multinode distributed training, whether to log once per node or just once on the main node.'}),_field_type=_FIELD), 'logging_dir': Field(name='logging_dir',type=typing.Union[str, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Tensorboard log dir.'}),_field_type=_FIELD), 'logging_first_step': Field(name='logging_first_step',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Log the first global_step'}),_field_type=_FIELD), 'logging_nan_inf_filter': Field(name='logging_nan_inf_filter',type=&lt;class 'bool'&gt;,default=True,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Filter nan and inf losses for logging.'}),_field_type=_FIELD), 'logging_steps': Field(name='logging_steps',type=&lt;class 'int'&gt;,default=500,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Log every X updates steps.'}),_field_type=_FIELD), 'logging_strategy': Field(name='logging_strategy',type=&lt;enum 'IntervalStrategy'&gt;,default='steps',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The logging strategy to use.'}),_field_type=_FIELD), 'lr_scheduler_type': Field(name='lr_scheduler_type',type=&lt;enum 'SchedulerType'&gt;,default='linear',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The scheduler type to use.'}),_field_type=_FIELD), 'max_grad_norm': Field(name='max_grad_norm',type=&lt;class 'float'&gt;,default=1.0,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Max gradient norm.'}),_field_type=_FIELD), 'max_steps': Field(name='max_steps',type=&lt;class 'int'&gt;,default=-1,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'If &gt; 0: set total number of training steps to perform. Override num_train_epochs.'}),_field_type=_FIELD), 'metric_for_best_model': Field(name='metric_for_best_model',type=typing.Union[str, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The metric to use to compare two different models.'}),_field_type=_FIELD), 'mp_parameters': Field(name='mp_parameters',type=&lt;class 'str'&gt;,default='',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Used by the SageMaker launcher to send mp-specific args. Ignored in Trainer'}),_field_type=_FIELD), 'no_cuda': Field(name='no_cuda',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Do not use CUDA even when it is available'}),_field_type=_FIELD), 'num_train_epochs': Field(name='num_train_epochs',type=&lt;class 'float'&gt;,default=3.0,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Total number of training epochs to perform.'}),_field_type=_FIELD), 'optim': Field(name='optim',type=&lt;enum 'OptimizerNames'&gt;,default='adamw_hf',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The optimizer to use.'}),_field_type=_FIELD), 'output_dir': Field(name='output_dir',type=&lt;class 'str'&gt;,default=&lt;dataclasses._MISSING_TYPE object&gt;,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The output directory where the model predictions and checkpoints will be written.'}),_field_type=_FIELD), 'overwrite_output_dir': Field(name='overwrite_output_dir',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Overwrite the content of the output directory. Use this to continue training if output_dir points to a checkpoint directory.'}),_field_type=_FIELD), 'past_index': Field(name='past_index',type=&lt;class 'int'&gt;,default=-1,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'If &gt;=0, uses the corresponding part of the output as the past state for next step.'}),_field_type=_FIELD), 'per_device_eval_batch_size': Field(name='per_device_eval_batch_size',type=&lt;class 'int'&gt;,default=8,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Batch size per GPU/TPU core/CPU for evaluation.'}),_field_type=_FIELD), 'per_device_train_batch_size': Field(name='per_device_train_batch_size',type=&lt;class 'int'&gt;,default=8,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Batch size per GPU/TPU core/CPU for training.'}),_field_type=_FIELD), 'per_gpu_eval_batch_size': Field(name='per_gpu_eval_batch_size',type=typing.Union[int, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Deprecated, the use of `--per_device_eval_batch_size` is preferred. Batch size per GPU/TPU core/CPU for evaluation.'}),_field_type=_FIELD), 'per_gpu_train_batch_size': Field(name='per_gpu_train_batch_size',type=typing.Union[int, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Deprecated, the use of `--per_device_train_batch_size` is preferred. Batch size per GPU/TPU core/CPU for training.'}),_field_type=_FIELD), 'prediction_loss_only': Field(name='prediction_loss_only',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'When performing evaluation and predictions, only returns the loss.'}),_field_type=_FIELD), 'push_to_hub': Field(name='push_to_hub',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether or not to upload the trained model to the model hub after training.'}),_field_type=_FIELD), 'push_to_hub_model_id': Field(name='push_to_hub_model_id',type=typing.Union[str, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The name of the repository to which push the `Trainer`.'}),_field_type=_FIELD), 'push_to_hub_organization': Field(name='push_to_hub_organization',type=typing.Union[str, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The name of the organization in with to which push the `Trainer`.'}),_field_type=_FIELD), 'push_to_hub_token': Field(name='push_to_hub_token',type=typing.Union[str, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The token to use to push to the Model Hub.'}),_field_type=_FIELD), 'ray_scope': Field(name='ray_scope',type=typing.Union[str, NoneType],default='last',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The scope to use when doing hyperparameter search with Ray. By default, `&quot;last&quot;` will be used. Ray will then use the last checkpoint of all trials, compare those, and select the best one. However, other options are also available. See the Ray documentation (https://docs.ray.io/en/latest/tune/api_docs/analysis.html#ray.tune.ExperimentAnalysis.get_best_trial) for more options.'}),_field_type=_FIELD), 'remove_unused_columns': Field(name='remove_unused_columns',type=typing.Union[str, NoneType],default='yes',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Remove columns not required by the model when using an nlp.Dataset.'}),_field_type=_FIELD), 'report_to': Field(name='report_to',type=typing.Union[str, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The list of integrations to report the results and logs to.A single string, but can contain multiple keys separated with comma: `i1,i2`'}),_field_type=_FIELD), 'resume_from_checkpoint': Field(name='resume_from_checkpoint',type=typing.Union[str, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The path to a folder with a valid checkpoint for your model.'}),_field_type=_FIELD), 'run_name': Field(name='run_name',type=typing.Union[str, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'An optional descriptor for the run. Notably used for wandb logging.'}),_field_type=_FIELD), 'save_on_each_node': Field(name='save_on_each_node',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'When doing multi-node distributed training, whether to save models and checkpoints on each node, or only on the main one'}),_field_type=_FIELD), 'save_steps': Field(name='save_steps',type=&lt;class 'int'&gt;,default=500,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Save checkpoint every X updates steps.'}),_field_type=_FIELD), 'save_strategy': Field(name='save_strategy',type=&lt;enum 'IntervalStrategy'&gt;,default='steps',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The checkpoint save strategy to use.'}),_field_type=_FIELD), 'save_total_limit': Field(name='save_total_limit',type=typing.Union[int, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Limit the total amount of checkpoints. Deletes the older checkpoints in the output_dir. Default is unlimited checkpoints'}),_field_type=_FIELD), 'seed': Field(name='seed',type=&lt;class 'int'&gt;,default=42,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Random seed that will be set at the beginning of training.'}),_field_type=_FIELD), 'sharded_ddp': Field(name='sharded_ddp',type=&lt;class 'str'&gt;,default='',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether or not to use sharded DDP training (in distributed training only). The base option should be `simple`, `zero_dp_2` or `zero_dp_3` and you can add CPU-offload to `zero_dp_2` or `zero_dp_3` like this: zero_dp_2 offload` or `zero_dp_3 offload`. You can add auto-wrap to `zero_dp_2` or with the same syntax: zero_dp_2 auto_wrap` or `zero_dp_3 auto_wrap`.'}),_field_type=_FIELD), 'skip_memory_metrics': Field(name='skip_memory_metrics',type=&lt;class 'bool'&gt;,default=True,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether or not to skip adding of memory profiler reports to metrics.'}),_field_type=_FIELD), 'tf32': Field(name='tf32',type=typing.Union[str, NoneType],default='no',default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether to enable tf32 mode, available in Ampere and newer GPU architectures. This is an experimental API and it may change.'}),_field_type=_FIELD), 'torchdynamo': Field(name='torchdynamo',type=typing.Union[str, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Sets up the backend compiler for TorchDynamo. TorchDynamo is a Python level JIT compiler designed to make unmodified PyTorch programs faster. TorchDynamo dynamically modifies the Python bytecode right before its executed. It rewrites Python bytecode to extract sequences of PyTorch operations and lifts them up into Fx graph. We can then pass these Fx graphs to other backend compilers. There are two options - eager and nvfuser. Eager defaults to pytorch eager and is useful for debugging. nvfuser path uses AOT Autograd and nvfuser compiler to optimize the models.', 'choices': ['eager', 'nvfuser']}),_field_type=_FIELD), 'tpu_metrics_debug': Field(name='tpu_metrics_debug',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Deprecated, the use of `--debug tpu_metrics_debug` is preferred. TPU: Whether to print debug metrics'}),_field_type=_FIELD), 'tpu_num_cores': Field(name='tpu_num_cores',type=typing.Union[int, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'TPU: Number of TPU cores (automatically passed by launcher script)'}),_field_type=_FIELD), 'use_ipex': Field(name='use_ipex',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': &quot;Use Intel extension for PyTorch when it is available, installation: 'https://github.com/intel/intel-extension-for-pytorch'&quot;}),_field_type=_FIELD), 'use_legacy_prediction_loop': Field(name='use_legacy_prediction_loop',type=&lt;class 'bool'&gt;,default=False,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Whether or not to use the legacy prediction_loop in the Trainer.'}),_field_type=_FIELD), 'warmup_ratio': Field(name='warmup_ratio',type=&lt;class 'float'&gt;,default=0.0,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Linear warmup over warmup_ratio fraction of total steps.'}),_field_type=_FIELD), 'warmup_steps': Field(name='warmup_steps',type=&lt;class 'int'&gt;,default=0,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Linear warmup over warmup_steps.'}),_field_type=_FIELD), 'weight_decay': Field(name='weight_decay',type=&lt;class 'float'&gt;,default=0.0,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'Weight decay for AdamW if we apply some.'}),_field_type=_FIELD), 'xpu_backend': Field(name='xpu_backend',type=typing.Union[str, NoneType],default=None,default_factory=&lt;dataclasses._MISSING_TYPE object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'help': 'The backend to be used for distributed training on Intel XPU.', 'choices': ['mpi', 'ccl']}),_field_type=_FIELD)}</em><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__dataclass_fields__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__dataclass_params__">
<code class="sig-name descname">__dataclass_params__</code><em class="property"> = _DataclassParams(init=True,repr=True,eq=True,order=False,unsafe_hash=False,frozen=False)</em><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__dataclass_params__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__doc__">
<code class="sig-name descname">__doc__</code><em class="property"> = '\n    GT4SD ships with a CLI to launch training. This conflicts with some data types\n    native in `transformers.training_arguments.TrainingArguments` especially iterables\n    which cannot be easily passed from CLI.\n    Therefore, this class changes the affected attributes to CLI compatible datatypes.\n    '</em><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__doc__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__eq__">
<code class="sig-name descname">__eq__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">other</span></em><span class="sig-paren">)</span><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__eq__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return self==value.</p>
</dd></dl>

<dl class="py attribute">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__hash__">
<code class="sig-name descname">__hash__</code><em class="property"> = None</em><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__hash__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">output_dir</span></em>, <em class="sig-param"><span class="n">overwrite_output_dir</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">do_train</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">do_eval</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">do_predict</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">evaluation_strategy</span><span class="o">=</span><span class="default_value">'no'</span></em>, <em class="sig-param"><span class="n">prediction_loss_only</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="default_value">8</span></em>, <em class="sig-param"><span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="default_value">8</span></em>, <em class="sig-param"><span class="n">per_gpu_train_batch_size</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">per_gpu_eval_batch_size</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">eval_accumulation_steps</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">eval_delay</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">learning_rate</span><span class="o">=</span><span class="default_value">5e-05</span></em>, <em class="sig-param"><span class="n">weight_decay</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">adam_beta1</span><span class="o">=</span><span class="default_value">0.9</span></em>, <em class="sig-param"><span class="n">adam_beta2</span><span class="o">=</span><span class="default_value">0.999</span></em>, <em class="sig-param"><span class="n">adam_epsilon</span><span class="o">=</span><span class="default_value">1e-08</span></em>, <em class="sig-param"><span class="n">max_grad_norm</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">num_train_epochs</span><span class="o">=</span><span class="default_value">3.0</span></em>, <em class="sig-param"><span class="n">max_steps</span><span class="o">=</span><span class="default_value">- 1</span></em>, <em class="sig-param"><span class="n">lr_scheduler_type</span><span class="o">=</span><span class="default_value">'linear'</span></em>, <em class="sig-param"><span class="n">warmup_ratio</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">warmup_steps</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">log_level</span><span class="o">=</span><span class="default_value">'passive'</span></em>, <em class="sig-param"><span class="n">log_level_replica</span><span class="o">=</span><span class="default_value">'passive'</span></em>, <em class="sig-param"><span class="n">log_on_each_node</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">logging_dir</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">logging_strategy</span><span class="o">=</span><span class="default_value">'steps'</span></em>, <em class="sig-param"><span class="n">logging_first_step</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">logging_steps</span><span class="o">=</span><span class="default_value">500</span></em>, <em class="sig-param"><span class="n">logging_nan_inf_filter</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">save_strategy</span><span class="o">=</span><span class="default_value">'steps'</span></em>, <em class="sig-param"><span class="n">save_steps</span><span class="o">=</span><span class="default_value">500</span></em>, <em class="sig-param"><span class="n">save_total_limit</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">save_on_each_node</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">no_cuda</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">seed</span><span class="o">=</span><span class="default_value">42</span></em>, <em class="sig-param"><span class="n">data_seed</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">jit_mode_eval</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">use_ipex</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">bf16</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">fp16</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">fp16_opt_level</span><span class="o">=</span><span class="default_value">'O1'</span></em>, <em class="sig-param"><span class="n">half_precision_backend</span><span class="o">=</span><span class="default_value">'auto'</span></em>, <em class="sig-param"><span class="n">bf16_full_eval</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">fp16_full_eval</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">tf32</span><span class="o">=</span><span class="default_value">'no'</span></em>, <em class="sig-param"><span class="n">local_rank</span><span class="o">=</span><span class="default_value">- 1</span></em>, <em class="sig-param"><span class="n">xpu_backend</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">tpu_num_cores</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">tpu_metrics_debug</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">debug</span><span class="o">=</span><span class="default_value">''</span></em>, <em class="sig-param"><span class="n">dataloader_drop_last</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">eval_steps</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">dataloader_num_workers</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">past_index</span><span class="o">=</span><span class="default_value">- 1</span></em>, <em class="sig-param"><span class="n">run_name</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">disable_tqdm</span><span class="o">=</span><span class="default_value">'no'</span></em>, <em class="sig-param"><span class="n">remove_unused_columns</span><span class="o">=</span><span class="default_value">'yes'</span></em>, <em class="sig-param"><span class="n">label_names</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">load_best_model_at_end</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">metric_for_best_model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">greater_is_better</span><span class="o">=</span><span class="default_value">'no'</span></em>, <em class="sig-param"><span class="n">ignore_data_skip</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">sharded_ddp</span><span class="o">=</span><span class="default_value">''</span></em>, <em class="sig-param"><span class="n">fsdp</span><span class="o">=</span><span class="default_value">''</span></em>, <em class="sig-param"><span class="n">fsdp_min_num_params</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">deepspeed</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">label_smoothing_factor</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">optim</span><span class="o">=</span><span class="default_value">'adamw_hf'</span></em>, <em class="sig-param"><span class="n">adafactor</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">group_by_length</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">length_column_name</span><span class="o">=</span><span class="default_value">'length'</span></em>, <em class="sig-param"><span class="n">report_to</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ddp_find_unused_parameters</span><span class="o">=</span><span class="default_value">'no'</span></em>, <em class="sig-param"><span class="n">ddp_bucket_cap_mb</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">dataloader_pin_memory</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">skip_memory_metrics</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">use_legacy_prediction_loop</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">push_to_hub</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">resume_from_checkpoint</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">hub_model_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">hub_strategy</span><span class="o">=</span><span class="default_value">'every_save'</span></em>, <em class="sig-param"><span class="n">hub_token</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">hub_private_repo</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">gradient_checkpointing</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">include_inputs_for_metrics</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">fp16_backend</span><span class="o">=</span><span class="default_value">'auto'</span></em>, <em class="sig-param"><span class="n">push_to_hub_model_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">push_to_hub_organization</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">push_to_hub_token</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">mp_parameters</span><span class="o">=</span><span class="default_value">''</span></em>, <em class="sig-param"><span class="n">auto_find_batch_size</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">full_determinism</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">torchdynamo</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ray_scope</span><span class="o">=</span><span class="default_value">'last'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="py attribute">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__module__">
<code class="sig-name descname">__module__</code><em class="property"> = 'gt4sd.training_pipelines.regression_transformer.utils'</em><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__module__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__repr__">
<code class="sig-name descname">__repr__</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.TransformersTrainingArgumentsCLI.__repr__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="gt4sd.training_pipelines.regression_transformer.utils.get_hf_training_arg_object">
<code class="sig-name descname">get_hf_training_arg_object</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">training_args</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/training_pipelines/regression_transformer/utils.html#get_hf_training_arg_object"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.training_pipelines.regression_transformer.utils.get_hf_training_arg_object" title="Permalink to this definition">¶</a></dt>
<dd><p>A method to convert a training_args Dictionary into a HuggingFace
<cite>TrainingArguments</cite> object.
This routine also takes care of removing arguments that are not necessary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>training_args</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – A dictionary of training arguments.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">TrainingArguments</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>object of type <cite>TrainingArguments</cite>.</p>
</dd>
</dl>
</dd></dl>

</section>
</section>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="gt4sd.training_pipelines.tests.html" class="btn btn-neutral float-right" title="gt4sd.training_pipelines.tests package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="gt4sd.training_pipelines.regression_transformer.implementation.html" class="btn btn-neutral float-left" title="gt4sd.training_pipelines.regression_transformer.implementation module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright GT4SD team 2022.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>