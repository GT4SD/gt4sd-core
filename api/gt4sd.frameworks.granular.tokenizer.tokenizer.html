

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>gt4sd.frameworks.granular.tokenizer.tokenizer module &mdash; gt4sd  documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="gt4sd.frameworks.granular.train package" href="gt4sd.frameworks.granular.train.html" />
    <link rel="prev" title="gt4sd.frameworks.granular.tokenizer package" href="gt4sd.frameworks.granular.tokenizer.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> gt4sd
          

          
            
            <img src="../_static/gt4sd_logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../source/gt4sd_inference_usage_md.html">Examples on how to use the GT4SD algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../source/gt4sd_algorithm_addition_md.html">Examples on how to add an algorithm to GT4SD</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="gt4sd.html">API of the gt4sd package</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="gt4sd.configuration.html">gt4sd.configuration module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gt4sd.conftest.html">gt4sd.conftest module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gt4sd.exceptions.html">gt4sd.exceptions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gt4sd.s3.html">gt4sd.s3 module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gt4sd.algorithms.html">gt4sd.algorithms package</a></li>
<li class="toctree-l2"><a class="reference internal" href="gt4sd.cli.html">gt4sd.cli package</a></li>
<li class="toctree-l2"><a class="reference internal" href="gt4sd.domains.html">gt4sd.domains package</a></li>
<li class="toctree-l2"><a class="reference internal" href="gt4sd.extras.html">gt4sd.extras package</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="gt4sd.frameworks.html">gt4sd.frameworks package</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="gt4sd.frameworks.enzeptional.html">gt4sd.frameworks.enzeptional package</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="gt4sd.frameworks.granular.html">gt4sd.frameworks.granular package</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="gt4sd.frameworks.granular.arg_parser.html">gt4sd.frameworks.granular.arg_parser package</a></li>
<li class="toctree-l4"><a class="reference internal" href="gt4sd.frameworks.granular.dataloader.html">gt4sd.frameworks.granular.dataloader package</a></li>
<li class="toctree-l4"><a class="reference internal" href="gt4sd.frameworks.granular.ml.html">gt4sd.frameworks.granular.ml package</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="gt4sd.frameworks.granular.tokenizer.html">gt4sd.frameworks.granular.tokenizer package</a></li>
<li class="toctree-l4"><a class="reference internal" href="gt4sd.frameworks.granular.train.html">gt4sd.frameworks.granular.train package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="gt4sd.frameworks.torch.html">gt4sd.frameworks.torch package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gt4sd.tests.html">gt4sd.tests package</a></li>
<li class="toctree-l2"><a class="reference internal" href="gt4sd.training_pipelines.html">gt4sd.training_pipelines package</a></li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">gt4sd</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="gt4sd.html">gt4sd package</a> &raquo;</li>
        
          <li><a href="gt4sd.frameworks.html">gt4sd.frameworks package</a> &raquo;</li>
        
          <li><a href="gt4sd.frameworks.granular.html">gt4sd.frameworks.granular package</a> &raquo;</li>
        
          <li><a href="gt4sd.frameworks.granular.tokenizer.html">gt4sd.frameworks.granular.tokenizer package</a> &raquo;</li>
        
      <li>gt4sd.frameworks.granular.tokenizer.tokenizer module</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/api/gt4sd.frameworks.granular.tokenizer.tokenizer.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="module-gt4sd.frameworks.granular.tokenizer.tokenizer">
<span id="gt4sd-frameworks-granular-tokenizer-tokenizer-module"></span><h1>gt4sd.frameworks.granular.tokenizer.tokenizer module<a class="headerlink" href="#module-gt4sd.frameworks.granular.tokenizer.tokenizer" title="Permalink to this headline">¶</a></h1>
<p>Tokenizers implementations.</p>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>Classes:</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSelfiesTokenizer" title="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSelfiesTokenizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BasicSelfiesTokenizer</span></code></a></p></td>
<td><p>Basic SELFIES tokenizer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSmilesTokenizer" title="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSmilesTokenizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BasicSmilesTokenizer</span></code></a></p></td>
<td><p>Basic SMILES tokenizer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer" title="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BasicTokenizer</span></code></a></p></td>
<td><p>Basic tokenizer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.GenericTokenizer" title="gt4sd.frameworks.granular.tokenizer.tokenizer.GenericTokenizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GenericTokenizer</span></code></a></p></td>
<td><p>Generic tokenizer that can build a vocabulary on the fly.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.SelfiesTokenizer" title="gt4sd.frameworks.granular.tokenizer.tokenizer.SelfiesTokenizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SelfiesTokenizer</span></code></a></p></td>
<td><p>SELFIES tokenizer that can build a vocabulary on the fly.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.SmilesTokenizer" title="gt4sd.frameworks.granular.tokenizer.tokenizer.SmilesTokenizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SmilesTokenizer</span></code></a></p></td>
<td><p>SMILES tokenizer that can build a vocabulary on the fly.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer" title="gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tokenizer</span></code></a></p></td>
<td><p>Tokenizer that can build a vocabulary on the fly.</p></td>
</tr>
</tbody>
</table>
<p>Functions:</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.load_vocab" title="gt4sd.frameworks.granular.tokenizer.tokenizer.load_vocab"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_vocab</span></code></a></p></td>
<td><p>Loads a vocabulary file into a dictionary.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.selfies_alphabet" title="gt4sd.frameworks.granular.tokenizer.tokenizer.selfies_alphabet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">selfies_alphabet</span></code></a></p></td>
<td><p>Legacy selfies 0.2.4 alphabet method.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.selfies_alphabet">
<code class="sig-name descname">selfies_alphabet</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#selfies_alphabet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.selfies_alphabet" title="Permalink to this definition">¶</a></dt>
<dd><p>Legacy selfies 0.2.4 alphabet method.</p>
<p>Adapted from: <a class="reference external" href="https://github.com/aspuru-guzik-group/selfies/blob/84122855ae76a928e1cb7d58796b8b47385a4359/selfies/selfies.py#L4">https://github.com/aspuru-guzik-group/selfies/blob/84122855ae76a928e1cb7d58796b8b47385a4359/selfies/selfies.py#L4</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>SELFIES list of tokens.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.load_vocab">
<code class="sig-name descname">load_vocab</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">vocab_file</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#load_vocab"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.load_vocab" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads a vocabulary file into a dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>vocab_file</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – vocabulary file.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>vocabulary mapping tokens to indices.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer">
<em class="property">class </em><code class="sig-name descname">BasicTokenizer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pad_token</span><span class="o">=</span><span class="default_value">'&lt;pad&gt;'</span></em>, <em class="sig-param"><span class="n">sos_token</span><span class="o">=</span><span class="default_value">'&lt;sos&gt;'</span></em>, <em class="sig-param"><span class="n">eos_token</span><span class="o">=</span><span class="default_value">'&lt;/s&gt;'</span></em>, <em class="sig-param"><span class="n">unk_token</span><span class="o">=</span><span class="default_value">'&lt;unk&gt;'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#BasicTokenizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Basic tokenizer.</p>
<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pad_token</span><span class="o">=</span><span class="default_value">'&lt;pad&gt;'</span></em>, <em class="sig-param"><span class="n">sos_token</span><span class="o">=</span><span class="default_value">'&lt;sos&gt;'</span></em>, <em class="sig-param"><span class="n">eos_token</span><span class="o">=</span><span class="default_value">'&lt;/s&gt;'</span></em>, <em class="sig-param"><span class="n">unk_token</span><span class="o">=</span><span class="default_value">'&lt;unk&gt;'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#BasicTokenizer.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs a BasicSmilesTokenizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pad_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – padding token. Defaults to ‘&lt;pad&gt;’.</p></li>
<li><p><strong>sos_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – start of sequence token. Defaults to ‘&lt;sos&gt;’.</p></li>
<li><p><strong>eos_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – end of sequence token. Defaults to ‘&lt;/s&gt;’.</p></li>
<li><p><strong>unk_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – unknown token. Defaults to ‘&lt;unk&gt;’.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer.tokenize">
<code class="sig-name descname">tokenize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">text</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#BasicTokenizer.tokenize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer.tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Tokenize input text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – text to tokenize.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>list of tokens.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer.build_vocab">
<code class="sig-name descname">build_vocab</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">smiles</span></em>, <em class="sig-param"><span class="n">vocab_file</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#BasicTokenizer.build_vocab"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer.build_vocab" title="Permalink to this definition">¶</a></dt>
<dd><p>Build and save a vocabulary given a SMILES list.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>smiles</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Iterable</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – iterable of SMILES.</p></li>
<li><p><strong>vocab_file</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – path to a file where the vocabulary is saved.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a list of all tokens in the vocabulary.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer.__dict__">
<code class="sig-name descname">__dict__</code><em class="property"> = mappingproxy({'__module__': 'gt4sd.frameworks.granular.tokenizer.tokenizer', '__doc__': 'Basic tokenizer.', '__init__': &lt;function BasicTokenizer.__init__&gt;, 'tokenize': &lt;function BasicTokenizer.tokenize&gt;, 'build_vocab': &lt;function BasicTokenizer.build_vocab&gt;, '__dict__': &lt;attribute '__dict__' of 'BasicTokenizer' objects&gt;, '__weakref__': &lt;attribute '__weakref__' of 'BasicTokenizer' objects&gt;, '__annotations__': {}})</em><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer.__dict__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer.__doc__">
<code class="sig-name descname">__doc__</code><em class="property"> = 'Basic tokenizer.'</em><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer.__doc__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer.__module__">
<code class="sig-name descname">__module__</code><em class="property"> = 'gt4sd.frameworks.granular.tokenizer.tokenizer'</em><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer.__module__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer.__weakref__">
<code class="sig-name descname">__weakref__</code><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer.__weakref__" title="Permalink to this definition">¶</a></dt>
<dd><p>list of weak references to the object (if defined)</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSmilesTokenizer">
<em class="property">class </em><code class="sig-name descname">BasicSmilesTokenizer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">regex_pattern</span><span class="o">=</span><span class="default_value">'(\\\\[[^\\\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\\\(|\\\\)|\\\\.|=|#|-|\\\\+|\\\\\\\\|\\\\/|:|~|&#64;|\\\\?|&gt;&gt;?|\\\\*|\\\\$|\\\\%[0-9]{2}|[0-9])'</span></em>, <em class="sig-param"><span class="n">pad_token</span><span class="o">=</span><span class="default_value">'&lt;pad&gt;'</span></em>, <em class="sig-param"><span class="n">sos_token</span><span class="o">=</span><span class="default_value">'&lt;sos&gt;'</span></em>, <em class="sig-param"><span class="n">eos_token</span><span class="o">=</span><span class="default_value">'&lt;/s&gt;'</span></em>, <em class="sig-param"><span class="n">unk_token</span><span class="o">=</span><span class="default_value">'&lt;unk&gt;'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#BasicSmilesTokenizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSmilesTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer" title="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer</span></code></a></p>
<p>Basic SMILES tokenizer.</p>
<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSmilesTokenizer.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">regex_pattern</span><span class="o">=</span><span class="default_value">'(\\\\[[^\\\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\\\(|\\\\)|\\\\.|=|#|-|\\\\+|\\\\\\\\|\\\\/|:|~|&#64;|\\\\?|&gt;&gt;?|\\\\*|\\\\$|\\\\%[0-9]{2}|[0-9])'</span></em>, <em class="sig-param"><span class="n">pad_token</span><span class="o">=</span><span class="default_value">'&lt;pad&gt;'</span></em>, <em class="sig-param"><span class="n">sos_token</span><span class="o">=</span><span class="default_value">'&lt;sos&gt;'</span></em>, <em class="sig-param"><span class="n">eos_token</span><span class="o">=</span><span class="default_value">'&lt;/s&gt;'</span></em>, <em class="sig-param"><span class="n">unk_token</span><span class="o">=</span><span class="default_value">'&lt;unk&gt;'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#BasicSmilesTokenizer.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSmilesTokenizer.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs a BasicSmilesTokenizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>regex_pattern</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – regex pattern. Defaults to SMI_REGEX_PATTERN.</p></li>
<li><p><strong>pad_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – padding token. Defaults to ‘&lt;pad&gt;’.</p></li>
<li><p><strong>sos_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – start of sequence token. Defaults to ‘&lt;sos&gt;’.</p></li>
<li><p><strong>eos_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – end of sequence token. Defaults to ‘&lt;/s&gt;’.</p></li>
<li><p><strong>unk_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – unknown token. Defaults to ‘&lt;unk&gt;’.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSmilesTokenizer.tokenize">
<code class="sig-name descname">tokenize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">text</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#BasicSmilesTokenizer.tokenize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSmilesTokenizer.tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Tokenize input text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – text to tokenize.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>list of tokens.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSmilesTokenizer.__doc__">
<code class="sig-name descname">__doc__</code><em class="property"> = 'Basic SMILES tokenizer.'</em><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSmilesTokenizer.__doc__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSmilesTokenizer.__module__">
<code class="sig-name descname">__module__</code><em class="property"> = 'gt4sd.frameworks.granular.tokenizer.tokenizer'</em><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSmilesTokenizer.__module__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSelfiesTokenizer">
<em class="property">class </em><code class="sig-name descname">BasicSelfiesTokenizer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pad_token</span><span class="o">=</span><span class="default_value">'&lt;pad&gt;'</span></em>, <em class="sig-param"><span class="n">sos_token</span><span class="o">=</span><span class="default_value">'&lt;sos&gt;'</span></em>, <em class="sig-param"><span class="n">eos_token</span><span class="o">=</span><span class="default_value">'&lt;/s&gt;'</span></em>, <em class="sig-param"><span class="n">unk_token</span><span class="o">=</span><span class="default_value">'&lt;unk&gt;'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#BasicSelfiesTokenizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSelfiesTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer" title="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer</span></code></a></p>
<p>Basic SELFIES tokenizer.</p>
<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSelfiesTokenizer.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pad_token</span><span class="o">=</span><span class="default_value">'&lt;pad&gt;'</span></em>, <em class="sig-param"><span class="n">sos_token</span><span class="o">=</span><span class="default_value">'&lt;sos&gt;'</span></em>, <em class="sig-param"><span class="n">eos_token</span><span class="o">=</span><span class="default_value">'&lt;/s&gt;'</span></em>, <em class="sig-param"><span class="n">unk_token</span><span class="o">=</span><span class="default_value">'&lt;unk&gt;'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#BasicSelfiesTokenizer.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSelfiesTokenizer.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs a BasicSelfiesTokenizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pad_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – padding token. Defaults to ‘&lt;pad&gt;’.</p></li>
<li><p><strong>sos_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – start of sequence token. Defaults to ‘&lt;sos&gt;’.</p></li>
<li><p><strong>eos_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – end of sequence token. Defaults to ‘&lt;/s&gt;’.</p></li>
<li><p><strong>unk_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – unknown token. Defaults to ‘&lt;unk&gt;’.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSelfiesTokenizer.smiles_to_selfies">
<code class="sig-name descname">smiles_to_selfies</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">smiles</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#BasicSelfiesTokenizer.smiles_to_selfies"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSelfiesTokenizer.smiles_to_selfies" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert a list of SMILES into SELFIES.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>smiles</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Iterable</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – a list of SMILES.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a list of SELFIES.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSelfiesTokenizer.tokenize">
<code class="sig-name descname">tokenize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">text</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#BasicSelfiesTokenizer.tokenize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSelfiesTokenizer.tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Tokenize input text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – text to tokenize.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>list of tokens.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSelfiesTokenizer.build_vocab">
<code class="sig-name descname">build_vocab</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">smiles</span></em>, <em class="sig-param"><span class="n">vocab_file</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#BasicSelfiesTokenizer.build_vocab"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSelfiesTokenizer.build_vocab" title="Permalink to this definition">¶</a></dt>
<dd><p>Build and save a vocabulary given a SMILES list.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>smiles</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Iterable</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – iterable of SMILES.</p></li>
<li><p><strong>vocab_file</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – path to a file where the vocabulary is saved.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a list of all tokens in the vocabulary.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSelfiesTokenizer.__doc__">
<code class="sig-name descname">__doc__</code><em class="property"> = 'Basic SELFIES tokenizer.'</em><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSelfiesTokenizer.__doc__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSelfiesTokenizer.__module__">
<code class="sig-name descname">__module__</code><em class="property"> = 'gt4sd.frameworks.granular.tokenizer.tokenizer'</em><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicSelfiesTokenizer.__module__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer">
<em class="property">class </em><code class="sig-name descname">Tokenizer</code><span class="sig-paren">(</span><em class="sig-param">vocab_file</em>, <em class="sig-param">basic_tokenizer=&lt;gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer object&gt;</em>, <em class="sig-param">smiles=[]</em>, <em class="sig-param">pad_token='&lt;pad&gt;'</em>, <em class="sig-param">sos_token='&lt;sos&gt;'</em>, <em class="sig-param">eos_token='&lt;/s&gt;'</em>, <em class="sig-param">unk_token='&lt;unk&gt;'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#Tokenizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Tokenizer that can build a vocabulary on the fly.</p>
<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">vocab_file</em>, <em class="sig-param">basic_tokenizer=&lt;gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer object&gt;</em>, <em class="sig-param">smiles=[]</em>, <em class="sig-param">pad_token='&lt;pad&gt;'</em>, <em class="sig-param">sos_token='&lt;sos&gt;'</em>, <em class="sig-param">eos_token='&lt;/s&gt;'</em>, <em class="sig-param">unk_token='&lt;unk&gt;'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#Tokenizer.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs a Tokenizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab_file</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – path to vocabulary file. If the file is not present, the provided SMILES list
is used to generate one.</p></li>
<li><p><strong>basic_tokenizer</strong> (<a class="reference internal" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer" title="gt4sd.frameworks.granular.tokenizer.tokenizer.BasicTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BasicTokenizer</span></code></a>) – a basic tokenizer. Defaults to BasicTokenizer character tokenizer.</p></li>
<li><p><strong>smiles</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – list of smiles. Default to empty list, used only if the vocabulary file does not exist.</p></li>
<li><p><strong>pad_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – padding token. Defaults to ‘&lt;pad&gt;’.</p></li>
<li><p><strong>sos_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – start of sequence token. Defaults to ‘&lt;sos&gt;’.</p></li>
<li><p><strong>eos_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – end of sequence token. Defaults to ‘&lt;/s&gt;’.</p></li>
<li><p><strong>unk_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – unknown token. Defaults to ‘&lt;unk&gt;’.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.vocab_size">
<em class="property">property </em><code class="sig-name descname">vocab_size</code><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.vocab_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Size of the vocabulary.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>vocabulary file.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.vocab_list">
<em class="property">property </em><code class="sig-name descname">vocab_list</code><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.vocab_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Return vocabulary tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>all tokens from the vocabulary.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.tokenize">
<code class="sig-name descname">tokenize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">text</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#Tokenizer.tokenize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Tokenize a given text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – text to tokenize.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>list of tokens.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.convert_tokens_to_ids">
<code class="sig-name descname">convert_tokens_to_ids</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokens</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#Tokenizer.convert_tokens_to_ids"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.convert_tokens_to_ids" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert tokens to indices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tokens</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – list of tokens.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>list of indices.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.convert_token_to_id">
<code class="sig-name descname">convert_token_to_id</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">token</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#Tokenizer.convert_token_to_id"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.convert_token_to_id" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert token to index.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – a token.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><dl class="simple">
<dt>index corresponding to the input token. Unknown token index if the input</dt><dd><p>token is not present in the vocabulary.</p>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.convert_id_to_token">
<code class="sig-name descname">convert_id_to_token</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">index</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#Tokenizer.convert_id_to_token"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.convert_id_to_token" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert index to token.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – an index.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><dl class="simple">
<dt>token corresponding to the input index. Unknown token if the input</dt><dd><p>index is not found.</p>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.add_padding_tokens">
<code class="sig-name descname">add_padding_tokens</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">token_ids</span></em>, <em class="sig-param"><span class="n">length</span></em>, <em class="sig-param"><span class="n">right</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#Tokenizer.add_padding_tokens"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.add_padding_tokens" title="Permalink to this definition">¶</a></dt>
<dd><p>Add padding token indices to the provided token indices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>token_ids</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – token indices.</p></li>
<li><p><strong>length</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – length of the sequence.</p></li>
<li><p><strong>right</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – wheter the padding is performed on the right. Defaults to True, if False
the padding happens on the left.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the padded sequence.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.__dict__">
<code class="sig-name descname">__dict__</code><em class="property"> = mappingproxy({'__module__': 'gt4sd.frameworks.granular.tokenizer.tokenizer', '__doc__': 'Tokenizer that can build a vocabulary on the fly.', '__init__': &lt;function Tokenizer.__init__&gt;, 'vocab_size': &lt;property object&gt;, 'vocab_list': &lt;property object&gt;, 'tokenize': &lt;function Tokenizer.tokenize&gt;, 'convert_tokens_to_ids': &lt;function Tokenizer.convert_tokens_to_ids&gt;, 'convert_token_to_id': &lt;function Tokenizer.convert_token_to_id&gt;, 'convert_id_to_token': &lt;function Tokenizer.convert_id_to_token&gt;, 'add_padding_tokens': &lt;function Tokenizer.add_padding_tokens&gt;, '__dict__': &lt;attribute '__dict__' of 'Tokenizer' objects&gt;, '__weakref__': &lt;attribute '__weakref__' of 'Tokenizer' objects&gt;, '__annotations__': {}})</em><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.__dict__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.__doc__">
<code class="sig-name descname">__doc__</code><em class="property"> = 'Tokenizer that can build a vocabulary on the fly.'</em><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.__doc__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.__module__">
<code class="sig-name descname">__module__</code><em class="property"> = 'gt4sd.frameworks.granular.tokenizer.tokenizer'</em><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.__module__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.__weakref__">
<code class="sig-name descname">__weakref__</code><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer.__weakref__" title="Permalink to this definition">¶</a></dt>
<dd><p>list of weak references to the object (if defined)</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.GenericTokenizer">
<em class="property">class </em><code class="sig-name descname">GenericTokenizer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">vocab_file</span></em>, <em class="sig-param"><span class="n">smiles</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">pad_token</span><span class="o">=</span><span class="default_value">'&lt;pad&gt;'</span></em>, <em class="sig-param"><span class="n">sos_token</span><span class="o">=</span><span class="default_value">'&lt;sos&gt;'</span></em>, <em class="sig-param"><span class="n">eos_token</span><span class="o">=</span><span class="default_value">'&lt;/s&gt;'</span></em>, <em class="sig-param"><span class="n">unk_token</span><span class="o">=</span><span class="default_value">'&lt;unk&gt;'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#GenericTokenizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.GenericTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer" title="gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer</span></code></a></p>
<p>Generic tokenizer that can build a vocabulary on the fly.</p>
<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.GenericTokenizer.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">vocab_file</span></em>, <em class="sig-param"><span class="n">smiles</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">pad_token</span><span class="o">=</span><span class="default_value">'&lt;pad&gt;'</span></em>, <em class="sig-param"><span class="n">sos_token</span><span class="o">=</span><span class="default_value">'&lt;sos&gt;'</span></em>, <em class="sig-param"><span class="n">eos_token</span><span class="o">=</span><span class="default_value">'&lt;/s&gt;'</span></em>, <em class="sig-param"><span class="n">unk_token</span><span class="o">=</span><span class="default_value">'&lt;unk&gt;'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#GenericTokenizer.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.GenericTokenizer.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs a GenericTokenizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab_file</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – path to vocabulary file. If the file is not present, the provided SMILES list
is used to generate one.</p></li>
<li><p><strong>smiles</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – list of smiles. Default to empty list, used only if the vocabulary file does not exist.</p></li>
<li><p><strong>pad_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – padding token. Defaults to ‘&lt;pad&gt;’.</p></li>
<li><p><strong>sos_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – start of sequence token. Defaults to ‘&lt;sos&gt;’.</p></li>
<li><p><strong>eos_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – end of sequence token. Defaults to ‘&lt;/s&gt;’.</p></li>
<li><p><strong>unk_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – unknown token. Defaults to ‘&lt;unk&gt;’.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.GenericTokenizer.__doc__">
<code class="sig-name descname">__doc__</code><em class="property"> = 'Generic tokenizer that can build a vocabulary on the fly.'</em><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.GenericTokenizer.__doc__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.GenericTokenizer.__module__">
<code class="sig-name descname">__module__</code><em class="property"> = 'gt4sd.frameworks.granular.tokenizer.tokenizer'</em><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.GenericTokenizer.__module__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.SmilesTokenizer">
<em class="property">class </em><code class="sig-name descname">SmilesTokenizer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">vocab_file</span></em>, <em class="sig-param"><span class="n">smiles</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">pad_token</span><span class="o">=</span><span class="default_value">'&lt;pad&gt;'</span></em>, <em class="sig-param"><span class="n">sos_token</span><span class="o">=</span><span class="default_value">'&lt;sos&gt;'</span></em>, <em class="sig-param"><span class="n">eos_token</span><span class="o">=</span><span class="default_value">'&lt;/s&gt;'</span></em>, <em class="sig-param"><span class="n">unk_token</span><span class="o">=</span><span class="default_value">'&lt;unk&gt;'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#SmilesTokenizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.SmilesTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer" title="gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer</span></code></a></p>
<p>SMILES tokenizer that can build a vocabulary on the fly.</p>
<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.SmilesTokenizer.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">vocab_file</span></em>, <em class="sig-param"><span class="n">smiles</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">pad_token</span><span class="o">=</span><span class="default_value">'&lt;pad&gt;'</span></em>, <em class="sig-param"><span class="n">sos_token</span><span class="o">=</span><span class="default_value">'&lt;sos&gt;'</span></em>, <em class="sig-param"><span class="n">eos_token</span><span class="o">=</span><span class="default_value">'&lt;/s&gt;'</span></em>, <em class="sig-param"><span class="n">unk_token</span><span class="o">=</span><span class="default_value">'&lt;unk&gt;'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#SmilesTokenizer.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.SmilesTokenizer.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs a SmilesTokenizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab_file</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – path to vocabulary file. If the file is not present, the provided SMILES list
is used to generate one.</p></li>
<li><p><strong>smiles</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – list of smiles. Default to empty list, used only if the vocabulary file does not exist.</p></li>
<li><p><strong>pad_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – padding token. Defaults to ‘&lt;pad&gt;’.</p></li>
<li><p><strong>sos_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – start of sequence token. Defaults to ‘&lt;sos&gt;’.</p></li>
<li><p><strong>eos_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – end of sequence token. Defaults to ‘&lt;/s&gt;’.</p></li>
<li><p><strong>unk_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – unknown token. Defaults to ‘&lt;unk&gt;’.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.SmilesTokenizer.__doc__">
<code class="sig-name descname">__doc__</code><em class="property"> = 'SMILES tokenizer that can build a vocabulary on the fly.'</em><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.SmilesTokenizer.__doc__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.SmilesTokenizer.__module__">
<code class="sig-name descname">__module__</code><em class="property"> = 'gt4sd.frameworks.granular.tokenizer.tokenizer'</em><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.SmilesTokenizer.__module__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.SelfiesTokenizer">
<em class="property">class </em><code class="sig-name descname">SelfiesTokenizer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">vocab_file</span></em>, <em class="sig-param"><span class="n">smiles</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">pad_token</span><span class="o">=</span><span class="default_value">'&lt;pad&gt;'</span></em>, <em class="sig-param"><span class="n">sos_token</span><span class="o">=</span><span class="default_value">'&lt;sos&gt;'</span></em>, <em class="sig-param"><span class="n">eos_token</span><span class="o">=</span><span class="default_value">'&lt;/s&gt;'</span></em>, <em class="sig-param"><span class="n">unk_token</span><span class="o">=</span><span class="default_value">'&lt;unk&gt;'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#SelfiesTokenizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.SelfiesTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer" title="gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">gt4sd.frameworks.granular.tokenizer.tokenizer.Tokenizer</span></code></a></p>
<p>SELFIES tokenizer that can build a vocabulary on the fly.</p>
<dl class="py method">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.SelfiesTokenizer.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">vocab_file</span></em>, <em class="sig-param"><span class="n">smiles</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">pad_token</span><span class="o">=</span><span class="default_value">'&lt;pad&gt;'</span></em>, <em class="sig-param"><span class="n">sos_token</span><span class="o">=</span><span class="default_value">'&lt;sos&gt;'</span></em>, <em class="sig-param"><span class="n">eos_token</span><span class="o">=</span><span class="default_value">'&lt;/s&gt;'</span></em>, <em class="sig-param"><span class="n">unk_token</span><span class="o">=</span><span class="default_value">'&lt;unk&gt;'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gt4sd/frameworks/granular/tokenizer/tokenizer.html#SelfiesTokenizer.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.SelfiesTokenizer.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs a SelfiesTokenizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab_file</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – path to vocabulary file. If the file is not present, the provided SMILES list
is used to generate one.</p></li>
<li><p><strong>smiles</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – list of smiles. Default to empty list, used only if the vocabulary file does not exist.</p></li>
<li><p><strong>pad_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – padding token. Defaults to ‘&lt;pad&gt;’.</p></li>
<li><p><strong>sos_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – start of sequence token. Defaults to ‘&lt;sos&gt;’.</p></li>
<li><p><strong>eos_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – end of sequence token. Defaults to ‘&lt;/s&gt;’.</p></li>
<li><p><strong>unk_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – unknown token. Defaults to ‘&lt;unk&gt;’.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.SelfiesTokenizer.__doc__">
<code class="sig-name descname">__doc__</code><em class="property"> = 'SELFIES tokenizer that can build a vocabulary on the fly.'</em><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.SelfiesTokenizer.__doc__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="gt4sd.frameworks.granular.tokenizer.tokenizer.SelfiesTokenizer.__module__">
<code class="sig-name descname">__module__</code><em class="property"> = 'gt4sd.frameworks.granular.tokenizer.tokenizer'</em><a class="headerlink" href="#gt4sd.frameworks.granular.tokenizer.tokenizer.SelfiesTokenizer.__module__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
</section>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="gt4sd.frameworks.granular.train.html" class="btn btn-neutral float-right" title="gt4sd.frameworks.granular.train package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="gt4sd.frameworks.granular.tokenizer.html" class="btn btn-neutral float-left" title="gt4sd.frameworks.granular.tokenizer package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright GT4SD team 2022.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>