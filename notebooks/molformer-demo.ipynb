{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference using the MolFormer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show how to perform inference using GT4SD and finetuned variants of the MolFormer model. The current existing models have been trained based on the datasets provided by the [official MolFormer repository]https://github.com/IBM/molformer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models for regression\n",
    "\n",
    "This method can be used for any regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dic/opt/miniconda3/envs/gt4sd_test/lib/python3.8/site-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2023-03-09 09:46:09.182229: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/dic/opt/miniconda3/envs/gt4sd_test/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/dic/opt/miniconda3/envs/gt4sd_test/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: (__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEENS6_INS2_12MemoryFormatEEE)\n",
      "  Referenced from: '/Users/dic/opt/miniconda3/envs/gt4sd_test/lib/python3.8/site-packages/torchvision/image.so'\n",
      "  Expected in: '/Users/dic/opt/miniconda3/envs/gt4sd_test/lib/python3.8/site-packages/torch/lib/libtorch_cpu.dylib'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/Users/dic/opt/miniconda3/envs/gt4sd_test/lib/python3.8/site-packages/moses/metrics/utils.py:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  _mcf.append(_pains, sort=True)['smarts'].values]\n",
      "clang: error: unsupported option '-fopenmp'\n",
      "clang: error: unsupported option '-fopenmp'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tape.models.modeling_utils:Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "09:46:26   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "INFO:toxsmi.utils.wrappers:Class weights are (1, 1).\n",
      "09:46:26   Class weights are (1, 1).\n",
      "INFO:toxsmi.utils.wrappers:Class weights are (1, 1).\n",
      "09:46:26   Class weights are (1, 1).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gt4sd.algorithms.core:runnning MolformerRegression with configuration=ConfigurablePropertyAlgorithmConfiguration(algorithm_version='molformer_alpha_public_test')\n",
      "09:46:28   runnning MolformerRegression with configuration=ConfigurablePropertyAlgorithmConfiguration(algorithm_version='molformer_alpha_public_test')\n",
      "INFO:gt4sd.algorithms.core:ensure artifacts for the application are present.\n",
      "09:46:28   ensure artifacts for the application are present.\n",
      "INFO:gt4sd.s3:starting syncing\n",
      "09:46:28   starting syncing\n",
      "INFO:gt4sd.s3:syncing complete\n",
      "09:46:28   syncing complete\n",
      "INFO:gt4sd.s3:starting syncing\n",
      "09:46:28   starting syncing\n",
      "INFO:gt4sd.s3:syncing complete\n",
      "09:46:28   syncing complete\n",
      "WARNING:gt4sd_molformer.finetune.finetune_pubchem_light:Apex is not installed. Molformer's training is not supported. Install Apex from source to enable training.\n",
      "09:46:29   Apex is not installed. Molformer's training is not supported. Install Apex from source to enable training.\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:29   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:29   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:29   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:29   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:29   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:29   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:29   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:29   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:29   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:29   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:29   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:29   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.finetune_pubchem_light:dropout is 0.1\n",
      "09:46:29   dropout is 0.1\n",
      "WARNING:gt4sd_molformer.finetune.finetune_pubchem_light:Apex is not installed. Molformer's training is not supported. Install Apex from source to enable training.\n",
      "09:46:30   Apex is not installed. Molformer's training is not supported. Install Apex from source to enable training.\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:30   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:30   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:30   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:30   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:30   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:31   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:31   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:31   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:31   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:31   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:31   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:31   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.finetune_pubchem_light:dropout is 0.1\n",
      "09:46:31   dropout is 0.1\n",
      "INFO:gt4sd_molformer.finetune.finetune_pubchem_light:Embeddings not found for 0 molecules\n",
      "09:46:31   Embeddings not found for 0 molecules\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[69.26847839355469]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gt4sd.properties.molecules import MOLECULE_PROPERTY_PREDICTOR_FACTORY\n",
    "\n",
    "property_class, parameters_class = MOLECULE_PROPERTY_PREDICTOR_FACTORY[\"molformer_regression\"]\n",
    "model = property_class(parameters_class(algorithm_version=\"molformer_alpha_public_test\"))\n",
    "\n",
    "model(input=[\"OC12COC3=NCC1C23\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models for classification\n",
    "\n",
    "This method can be used for any binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gt4sd.algorithms.core:runnning MolformerClassification with configuration=ConfigurablePropertyAlgorithmConfiguration(algorithm_version='molformer_bace_public_test')\n",
      "09:46:32   runnning MolformerClassification with configuration=ConfigurablePropertyAlgorithmConfiguration(algorithm_version='molformer_bace_public_test')\n",
      "INFO:gt4sd.algorithms.core:ensure artifacts for the application are present.\n",
      "09:46:32   ensure artifacts for the application are present.\n",
      "INFO:gt4sd.s3:starting syncing\n",
      "09:46:32   starting syncing\n",
      "INFO:gt4sd.s3:syncing complete\n",
      "09:46:32   syncing complete\n",
      "INFO:gt4sd.s3:starting syncing\n",
      "09:46:32   starting syncing\n",
      "INFO:gt4sd.s3:syncing complete\n",
      "09:46:32   syncing complete\n",
      "WARNING:gt4sd_molformer.finetune.finetune_pubchem_light_classification:Apex is not installed. Molformer's training is not supported. Install Apex from source to enable training.\n",
      "09:46:32   Apex is not installed. Molformer's training is not supported. Install Apex from source to enable training.\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:32   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:32   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:32   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:33   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:33   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:33   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:33   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:33   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:33   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:33   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:33   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:33   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.finetune_pubchem_light_classification:dropout is 0.1\n",
      "09:46:33   dropout is 0.1\n",
      "WARNING:gt4sd_molformer.finetune.finetune_pubchem_light_classification:Apex is not installed. Molformer's training is not supported. Install Apex from source to enable training.\n",
      "09:46:33   Apex is not installed. Molformer's training is not supported. Install Apex from source to enable training.\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:33   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:33   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:33   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:33   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:33   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:33   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:33   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:33   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:34   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:34   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:34   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:34   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.finetune_pubchem_light_classification:dropout is 0.1\n",
      "09:46:34   dropout is 0.1\n",
      "INFO:gt4sd_molformer.finetune.finetune_pubchem_light_classification:Dropped 0 invalid smiles\n",
      "09:46:34   Dropped 0 invalid smiles\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gt4sd.properties.molecules import MOLECULE_PROPERTY_PREDICTOR_FACTORY\n",
    "\n",
    "property_class, parameters_class = MOLECULE_PROPERTY_PREDICTOR_FACTORY[\"molformer_classification\"]\n",
    "model = property_class(parameters_class(algorithm_version=\"molformer_bace_public_test\"))\n",
    "\n",
    "model(input=[\"OC12COC3=NCC1C23\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Molformer for multiclass classification\n",
    "\n",
    "This method can be used for any multiclass classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gt4sd.algorithms.core:runnning MolformerMultitaskClassification with configuration=ConfigurablePropertyAlgorithmConfiguration(algorithm_version='molformer_clintox_test')\n",
      "09:46:34   runnning MolformerMultitaskClassification with configuration=ConfigurablePropertyAlgorithmConfiguration(algorithm_version='molformer_clintox_test')\n",
      "INFO:gt4sd.algorithms.core:ensure artifacts for the application are present.\n",
      "09:46:34   ensure artifacts for the application are present.\n",
      "INFO:gt4sd.s3:starting syncing\n",
      "09:46:34   starting syncing\n",
      "INFO:gt4sd.s3:syncing complete\n",
      "09:46:34   syncing complete\n",
      "INFO:gt4sd.s3:starting syncing\n",
      "09:46:34   starting syncing\n",
      "INFO:gt4sd.s3:syncing complete\n",
      "09:46:34   syncing complete\n",
      "WARNING:gt4sd_molformer.finetune.finetune_pubchem_light_classification_multitask:Apex is not installed. Molformer's training is not supported. Install Apex from source to enable training.\n",
      "09:46:34   Apex is not installed. Molformer's training is not supported. Install Apex from source to enable training.\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:34   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:34   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.finetune_pubchem_light_classification_multitask:dropout is 0.1\n",
      "09:46:35   dropout is 0.1\n",
      "WARNING:gt4sd_molformer.finetune.finetune_pubchem_light_classification_multitask:Apex is not installed. Molformer's training is not supported. Install Apex from source to enable training.\n",
      "09:46:35   Apex is not installed. Molformer's training is not supported. Install Apex from source to enable training.\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.ft_rotate_attention.ft_attention_layer:Using Rotation Embedding\n",
      "09:46:35   Using Rotation Embedding\n",
      "INFO:gt4sd_molformer.finetune.finetune_pubchem_light_classification_multitask:dropout is 0.1\n",
      "09:46:36   dropout is 0.1\n",
      "INFO:gt4sd_molformer.finetune.finetune_pubchem_light_classification_multitask:Dropped 0 invalid smiles\n",
      "09:46:36   Dropped 0 invalid smiles\n",
      "tensor([[0.9947, 0.0075]])\n",
      "['FDA_APPROVED']\n"
     ]
    }
   ],
   "source": [
    "property_class, parameters_class = MOLECULE_PROPERTY_PREDICTOR_FACTORY[\"molformer_multitask_classification\"]\n",
    "model = property_class(parameters_class(algorithm_version=\"molformer_clintox_test\"))\n",
    "\n",
    "print(model([\"Ic1cc(ccc1)C[NH2+]C[C@@H](O)[C@@H](NC(=O)c1cc(cc(c1)C)C(=O)N(CCC)CCC)Cc1cc(F)cc(F)c1\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "7f6df040e92be56c42e1ba5ffdd58832f97e24eff2af0498cbc88845f2e95a48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
